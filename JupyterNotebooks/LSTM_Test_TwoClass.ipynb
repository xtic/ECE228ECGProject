{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two-Class EEG Classification using LSTM-based RNN\n",
    "## Here, we develop a baseline model for using an RNN to perform time-series prediction for one of two motor\n",
    "## imagery (MI) tasks. The data from the file CLA_SubjectJ-170508-3St-LRHand-Inter.mat is processed and we\n",
    "## only keep the data points that pertain to the left and right hand MI tasks. Each of the MI task data consists\n",
    "## of 170 time steps, with each time step consisting of 22 inputs. In other words, we pass the current sample for\n",
    "## of the 22 channels for each time step. At the end of the 170 time step, we send the output of the LSTM layers\n",
    "## to a Dense layer with two outputs. To ease the classification at the outer layer, we have converted the class\n",
    "## into a one-hot encoding of zeros and ones, and use the sigmoid unit at the output to match the output range.\n",
    "\n",
    "## Preliminary results:\n",
    "## Performance on training set is 100% classification rate after around 30 to 40 epochs.\n",
    "## Performance on test set is around 60% - 68%.\n",
    "\n",
    "## Potential problems:\n",
    "## The total amount of data is relatively low. Can it be possible to combine multiple subject's L/R Hand MI data\n",
    "## into one unified data set?\n",
    "## Can also possible increase the size of the data set by doing some data augmentations.\n",
    "## For example, injecting some noise into the existing EEG data to create more test data?\n",
    "\n",
    "## Followup/TODO:\n",
    "## Use pre-implemented common spatial patterns for feature extraction: avialable here: https://github.com/spolsley/common-spatial-patterns\n",
    "## Try using a relatively simple non-linear energy operator as a pre-emphasis step on the data to see if it helps generalize\n",
    "## the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-18.   -3.6  -6.6 ...  -9.   -7.2  -2.4]\n",
      " [-19.2  -0.   -8.4 ...  -8.4 -11.4  -9. ]\n",
      " [-12.    1.8  -1.2 ...   2.4   3.6   5.4]\n",
      " ...\n",
      " [ -6.    5.4   3.  ...   5.4   4.2   3.6]\n",
      " [ -8.4   7.2   3.  ...   4.8   6.6   6. ]\n",
      " [ -1.2  -1.2  -1.8 ...  -0.   -0.   -0. ]]\n",
      "Number of samples: 621892\n",
      "Dataset ID: 201705081338.32BEA9DD\n",
      "Channel names: [array(['Fp1'], dtype='<U3') array(['Fp2'], dtype='<U3')\n",
      " array(['F3'], dtype='<U2') array(['F4'], dtype='<U2')\n",
      " array(['C3'], dtype='<U2') array(['C4'], dtype='<U2')\n",
      " array(['P3'], dtype='<U2') array(['P4'], dtype='<U2')\n",
      " array(['O1'], dtype='<U2') array(['O2'], dtype='<U2')\n",
      " array(['A1'], dtype='<U2') array(['A2'], dtype='<U2')\n",
      " array(['F7'], dtype='<U2') array(['F8'], dtype='<U2')\n",
      " array(['T3'], dtype='<U2') array(['T4'], dtype='<U2')\n",
      " array(['T5'], dtype='<U2') array(['T6'], dtype='<U2')\n",
      " array(['Fz'], dtype='<U2') array(['Cz'], dtype='<U2')\n",
      " array(['Pz'], dtype='<U2')]\n"
     ]
    }
   ],
   "source": [
    "## This file is used to split data into series of arrays and their corresponding MI task.\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "file = sio.loadmat('../mat_files/CLA-SubjectJ-170508-3St-LRHand-Inter.mat') #replace with .mat file name\n",
    "header=file['__header__']\n",
    "version=file['__version__']\n",
    "glob=file['__globals__']\n",
    "ans=file['ans']\n",
    "\n",
    "\n",
    "x=file['x']\n",
    "o=file['o'][0][0]\n",
    "data=o['data']\n",
    "data = np.transpose(data)\n",
    "print(data)\n",
    "nS=o['nS'][0][0]\n",
    "#values of structure seem to be 2D numpy arrays, if originally a scalar in Matlab.\n",
    "#use [0][0] to get scalar.\n",
    "print(\"Number of samples: {numSamples}\".format(numSamples=nS))\n",
    "test=o['id'][0] #id value became a 1D array of size 1 for some reason. use [0] to get value\n",
    "print(\"Dataset ID: {id}\".format(id=test))\n",
    "chnames=o['chnames'][:,0] #[:,0] converts from 2D array back to 1D array\n",
    "print(\"Channel names: {channelNames}\".format(channelNames=chnames))\n",
    "markers = o['marker']\n",
    "## The markers are all still individual arrays of size 1x1, so we convert them to an array with single values\n",
    "markersArray = []\n",
    "for marker in markers:\n",
    "    markersArray.append(marker[0])\n",
    "markersArray = np.asarray(markersArray)\n",
    "#For this dataset, the markers are 0, 1, or 2.\n",
    "# 1 - Left Hand MI, 2 - Right Hand MI, 3 - Passive State, 0 - Rest (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of index changes: 1800\n",
      "Number of arrays in data split: 1800\n",
      "Number of marker targets: 1800\n"
     ]
    }
   ],
   "source": [
    "## Find the starting indeces where the marker changes\n",
    "changeIdxs = np.where(np.transpose(markersArray)[:-1] != np.transpose(markersArray)[1:])[0]\n",
    "print(\"Number of index changes: {idxChanges}\".format(idxChanges=changeIdxs.shape[0]))\n",
    "## Split the data so that it has its matching marker\n",
    "dataSplit = np.array_split(data, changeIdxs[:-1], axis=1)\n",
    "splitCount = 0\n",
    "for splitData in dataSplit:\n",
    "    splitCount += 1\n",
    "print(\"Number of arrays in data split: {num}\".format(num=splitCount))\n",
    "## Retrieve the marker values for each of the change indeces (changeIdxs)\n",
    "markerTargets = markersArray[changeIdxs];\n",
    "print(\"Number of marker targets: {numTargets}\".format(numTargets=markerTargets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Apply CSP, we first only get the indeces for MI tasks 1 and 2 (left and right hand, respectively.)\n",
    "LeftIdxs = np.where(markerTargets == 1)\n",
    "RightIdxs = np.where(markerTargets == 2)\n",
    "numLeftIdx = LeftIdxs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 170, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftData = [];\n",
    "for leftIndex in LeftIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[leftIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        leftData.append(np.transpose(dataSplit[leftIndex]))\n",
    "leftData = np.asarray(leftData)\n",
    "leftData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 170, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightData = [];\n",
    "for rightIndex in RightIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[rightIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        rightData.append(np.transpose(dataSplit[rightIndex]))\n",
    "rightData = np.asarray(rightData)\n",
    "rightData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep the top 288 samples, so that left and right data are equal\n",
    "rightDataSub = rightData[1:289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrData Shape: (576, 170, 22)\tmarkerTargets Shape: (576, 2)\n"
     ]
    }
   ],
   "source": [
    "#Construct the target array and merge the data\n",
    "leftTargets = np.tile(np.array([1,0]),(288,1))\n",
    "rightTargets = np.tile(np.array([0,1]), (288,1))\n",
    "markerTargets = np.vstack((leftTargets, rightTargets))\n",
    "lrData = np.vstack((leftData, rightDataSub))\n",
    "\n",
    "#Sanity Check\n",
    "print(\"lrData Shape: {arg1}\\tmarkerTargets Shape: {arg2}\".format(arg1=lrData.shape, arg2=markerTargets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle the data\n",
    "lrData, markerTargets = shuffle(lrData, markerTargets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "lrDataTrain, lrDataTest, markerTargetsTrain, markerTargetsTest = train_test_split(lrData, markerTargets, test_size=0.3, random_state=1)\n",
    "markerTargetsTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "lrDataTrainRe = lrDataTrain.reshape((lrDataTrain.shape[0], lrDataTrain.shape[1], lrDataTrain.shape[2]))\n",
    "lrDataTestRe = lrDataTest.reshape((lrDataTest.shape[0], lrDataTest.shape[1], lrDataTest.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the model\n",
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,lrDataTrainRe.shape[1], lrDataTrainRe.shape[2]), return_sequences=True))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "LSTM_EEG.add(Dense((2),activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 170, 100)          49200     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 79,502\n",
      "Trainable params: 79,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "26/26 - 2s - loss: 0.6788 - accuracy: 0.5806\n",
      "Epoch 2/30\n",
      "26/26 - 2s - loss: 0.5982 - accuracy: 0.6700\n",
      "Epoch 3/30\n",
      "26/26 - 2s - loss: 0.5424 - accuracy: 0.7122\n",
      "Epoch 4/30\n",
      "26/26 - 2s - loss: 0.5325 - accuracy: 0.7370\n",
      "Epoch 5/30\n",
      "26/26 - 2s - loss: 0.4419 - accuracy: 0.8040\n",
      "Epoch 6/30\n",
      "26/26 - 2s - loss: 0.4109 - accuracy: 0.7965\n",
      "Epoch 7/30\n",
      "26/26 - 2s - loss: 0.3802 - accuracy: 0.8337\n",
      "Epoch 8/30\n",
      "26/26 - 2s - loss: 0.3880 - accuracy: 0.8213\n",
      "Epoch 9/30\n",
      "26/26 - 2s - loss: 0.2569 - accuracy: 0.8908\n",
      "Epoch 10/30\n",
      "26/26 - 2s - loss: 0.3459 - accuracy: 0.8486\n",
      "Epoch 11/30\n",
      "26/26 - 2s - loss: 0.2786 - accuracy: 0.8710\n",
      "Epoch 12/30\n",
      "26/26 - 2s - loss: 0.2127 - accuracy: 0.9156\n",
      "Epoch 13/30\n",
      "26/26 - 2s - loss: 0.2770 - accuracy: 0.8883\n",
      "Epoch 14/30\n",
      "26/26 - 2s - loss: 0.2545 - accuracy: 0.8983\n",
      "Epoch 15/30\n",
      "26/26 - 3s - loss: 0.1220 - accuracy: 0.9653\n",
      "Epoch 16/30\n",
      "26/26 - 2s - loss: 0.2056 - accuracy: 0.9280\n",
      "Epoch 17/30\n",
      "26/26 - 2s - loss: 0.1693 - accuracy: 0.9256\n",
      "Epoch 18/30\n",
      "26/26 - 2s - loss: 0.2190 - accuracy: 0.9032\n",
      "Epoch 19/30\n",
      "26/26 - 2s - loss: 0.1367 - accuracy: 0.9504\n",
      "Epoch 20/30\n",
      "26/26 - 2s - loss: 0.0779 - accuracy: 0.9777\n",
      "Epoch 21/30\n",
      "26/26 - 2s - loss: 0.0850 - accuracy: 0.9628\n",
      "Epoch 22/30\n",
      "26/26 - 2s - loss: 0.1052 - accuracy: 0.9628\n",
      "Epoch 23/30\n",
      "26/26 - 2s - loss: 0.2789 - accuracy: 0.8784\n",
      "Epoch 24/30\n",
      "26/26 - 2s - loss: 0.1454 - accuracy: 0.9479\n",
      "Epoch 25/30\n",
      "26/26 - 2s - loss: 0.0499 - accuracy: 0.9851\n",
      "Epoch 26/30\n",
      "26/26 - 2s - loss: 0.0415 - accuracy: 0.9901\n",
      "Epoch 27/30\n",
      "26/26 - 2s - loss: 0.0229 - accuracy: 0.9950\n",
      "Epoch 28/30\n",
      "26/26 - 2s - loss: 0.0132 - accuracy: 0.9975\n",
      "Epoch 29/30\n",
      "26/26 - 2s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26/26 - 2s - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = LSTM_EEG.fit(lrDataTrain, markerTargetsTrain, epochs=30,verbose=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest = LSTM_EEG.predict(lrDataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest>0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonArrayTest = predictionsTest == markerTargetsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = lrDataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(lrDataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = lrDataTrain.shape[0] - correctCountTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "Test Performance:\n",
      "Correct MI Prediction: 403\n",
      "Incorrect MI Prediction: 0\n",
      "Percent Accuracy: 100.000%\n",
      "#################################\n",
      "#################################\n",
      "Test Performance:\n",
      "Correct MI Prediction: 110\n",
      "Incorrect MI Prediction: 63\n",
      "Percent Accuracy: 63.584%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Test Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, (correctCountTrain*100/lrDataTrain.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Test Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, (correctCountTest*100/lrDataTest.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
