{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Five finger (5F) EEG Classification using LSTM-based RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.    -0.    -0.   ...  42.98 -11.25 -54.89]\n",
      " [ -0.    -0.    -0.   ...  37.77  -3.2  -57.64]\n",
      " [ -0.    -0.    -0.   ...  36.85  -3.78 -50.66]\n",
      " ...\n",
      " [ -0.    -0.    -0.   ...   7.51 -19.17 -41.75]\n",
      " [ -0.    -0.    -0.   ...  23.26  -0.6  -15.94]\n",
      " [ -0.    -0.    -0.   ...  24.24   6.41 -14.74]]\n",
      "Number of samples: 3596000\n",
      "Dataset ID: 201603111905.D091BB44\n",
      "Channel names: [array(['Fp1'], dtype='<U3') array(['Fp2'], dtype='<U3')\n",
      " array(['F3'], dtype='<U2') array(['F4'], dtype='<U2')\n",
      " array(['C3'], dtype='<U2') array(['C4'], dtype='<U2')\n",
      " array(['P3'], dtype='<U2') array(['P4'], dtype='<U2')\n",
      " array(['O1'], dtype='<U2') array(['O2'], dtype='<U2')\n",
      " array(['A1'], dtype='<U2') array(['A2'], dtype='<U2')\n",
      " array(['F7'], dtype='<U2') array(['F8'], dtype='<U2')\n",
      " array(['T3'], dtype='<U2') array(['T4'], dtype='<U2')\n",
      " array(['T5'], dtype='<U2') array(['T6'], dtype='<U2')\n",
      " array(['Fz'], dtype='<U2') array(['Cz'], dtype='<U2')\n",
      " array(['Pz'], dtype='<U2') array(['X5'], dtype='<U2')]\n"
     ]
    }
   ],
   "source": [
    "## This file is used to split data into series of arrays and their corresponding MI task.\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "file = sio.loadmat('../../../matDown/5F_Data/5F-SubjectB-160311-5St-SGLHand-HFREQ.mat') #replace with .mat file name\n",
    "header=file['__header__']\n",
    "version=file['__version__']\n",
    "glob=file['__globals__']\n",
    "#ans=file['ans']\n",
    "\n",
    "\n",
    "#x=file['x']\n",
    "o=file['o'][0][0]\n",
    "data=o['data']\n",
    "data = np.transpose(data)\n",
    "data = data[0:21,:];\n",
    "print(data)\n",
    "nS=o['nS'][0][0]\n",
    "#values of structure seem to be 2D numpy arrays, if originally a scalar in Matlab.\n",
    "#use [0][0] to get scalar.\n",
    "print(\"Number of samples: {numSamples}\".format(numSamples=nS))\n",
    "test=o['id'][0] #id value became a 1D array of size 1 for some reason. use [0] to get value\n",
    "print(\"Dataset ID: {id}\".format(id=test))\n",
    "chnames=o['chnames'][:,0] #[:,0] converts from 2D array back to 1D array\n",
    "print(\"Channel names: {channelNames}\".format(channelNames=chnames))\n",
    "markers = o['marker']\n",
    "## The markers are all still individual arrays of size 1x1, so we convert them to an array with single values\n",
    "markersArray = []\n",
    "for marker in markers:\n",
    "    markersArray.append(marker[0])\n",
    "markersArray = np.asarray(markersArray)\n",
    "\n",
    "#################################\n",
    "#################################\n",
    "#5F interaction paradigm\n",
    "#1-thumb MI, 2-index finger MI, 3-middle finger MI, 4-ring finger MI, 5-pinkie finger MI\n",
    "\n",
    "#all paradigms\n",
    "#99-initial relaxation period\n",
    "#91-inter-session rest break period\n",
    "#92-experiment end\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSP File from: https://github.com/spolsley/common-spatial-patterns\n",
    "\n",
    "# CSP takes any number of arguments, but each argument must be a collection of trials associated with a task\n",
    "# That is, for N tasks, N arrays are passed to CSP each with dimensionality (# of trials of task N) x (feature vector)\n",
    "# Trials may be of any dimension, provided that each trial for each task has the same dimensionality,\n",
    "# otherwise there can be no spatial filtering since the trials cannot be compared\n",
    "def CSP(*tasks):\n",
    "\tif len(tasks) < 2:\n",
    "\t\tprint(\"Must have at least 2 tasks for filtering.\")\n",
    "\t\treturn (None,) * len(tasks)\n",
    "\telse:\n",
    "\t\tfilters = ()\n",
    "\t\t# CSP algorithm\n",
    "\t\t# For each task x, find the mean variances Rx and not_Rx, which will be used to compute spatial filter SFx\n",
    "\t\titerator = range(0,len(tasks))\n",
    "\t\tfor x in iterator:\n",
    "\t\t\t# Find Rx\n",
    "\t\t\tRx = covarianceMatrix(tasks[x][0])\n",
    "\t\t\tfor t in range(1,len(tasks[x])):\n",
    "\t\t\t\tRx += covarianceMatrix(tasks[x][t])\n",
    "\t\t\tRx = Rx / len(tasks[x])\n",
    "\n",
    "\t\t\t# Find not_Rx\n",
    "\t\t\tcount = 0\n",
    "\t\t\tnot_Rx = Rx * 0\n",
    "\t\t\tfor not_x in [element for element in iterator if element != x]:\n",
    "\t\t\t\tfor t in range(0,len(tasks[not_x])):\n",
    "\t\t\t\t\tnot_Rx += covarianceMatrix(tasks[not_x][t])\n",
    "\t\t\t\t\tcount += 1\n",
    "\t\t\tnot_Rx = not_Rx / count\n",
    "\n",
    "\t\t\t# Find the spatial filter SFx\n",
    "\t\t\tSFx = spatialFilter(Rx,not_Rx)\n",
    "\t\t\tfilters += (SFx,)\n",
    "\n",
    "\t\t\t# Special case: only two tasks, no need to compute any more mean variances\n",
    "\t\t\tif len(tasks) == 2:\n",
    "\t\t\t\tfilters += (spatialFilter(not_Rx,Rx),)\n",
    "\t\t\t\tbreak\n",
    "\t\treturn filters\n",
    "\n",
    "# covarianceMatrix takes a matrix A and returns the covariance matrix, scaled by the variance\n",
    "def covarianceMatrix(A):\n",
    "\tCa = np.dot(A,np.transpose(A))/np.trace(np.dot(A,np.transpose(A)))\n",
    "\treturn Ca\n",
    "\n",
    "# spatialFilter returns the spatial filter SFa for mean covariance matrices Ra and Rb\n",
    "def spatialFilter(Ra,Rb):\n",
    "\tR = Ra + Rb\n",
    "\tE,U = la.eig(R)\n",
    "\n",
    "\t# CSP requires the eigenvalues E and eigenvector U be sorted in descending order\n",
    "\tord = np.argsort(E)\n",
    "\tord = ord[::-1] # argsort gives ascending order, flip to get descending\n",
    "\tE = E[ord]\n",
    "\tU = U[:,ord]\n",
    "\n",
    "\t# Find the whitening transformation matrix\n",
    "\tP = np.dot(np.sqrt(la.inv(np.diag(E))),np.transpose(U))\n",
    "\n",
    "\t# The mean covariance matrices may now be transformed\n",
    "\tSa = np.dot(P,np.dot(Ra,np.transpose(P)))\n",
    "\tSb = np.dot(P,np.dot(Rb,np.transpose(P)))\n",
    "\n",
    "\t# Find and sort the generalized eigenvalues and eigenvector\n",
    "\tE1,U1 = la.eig(Sa,Sb)\n",
    "\tord1 = np.argsort(E1)\n",
    "\tord1 = ord1[::-1]\n",
    "\tE1 = E1[ord1]\n",
    "\tU1 = U1[:,ord1]\n",
    "\n",
    "\t# The projection matrix (the spatial filter) may now be obtained\n",
    "\tSFa = np.dot(np.transpose(U1),P)\n",
    "\treturn SFa.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of index changes: 1934\n",
      "Number of arrays in data split: 1934\n",
      "Number of marker targets: 1934\n"
     ]
    }
   ],
   "source": [
    "## Find the starting indeces where the marker changes\n",
    "changeIdxs = np.where(np.transpose(markersArray)[:-1] != np.transpose(markersArray)[1:])[0]\n",
    "print(\"Number of index changes: {idxChanges}\".format(idxChanges=changeIdxs.shape[0]))\n",
    "## Split the data so that it has its matching marker\n",
    "dataSplit = np.array_split(data, changeIdxs[:-1], axis=1)\n",
    "splitCount = 0\n",
    "for splitData in dataSplit:\n",
    "    splitCount += 1\n",
    "print(\"Number of arrays in data split: {num}\".format(num=splitCount))\n",
    "## Retrieve the marker values for each of the change indeces (changeIdxs)\n",
    "markerTargets = markersArray[changeIdxs];\n",
    "print(\"Number of marker targets: {numTargets}\".format(numTargets=markerTargets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thumb Marker Count: (209,)\tSize of First: (21,4635)\n",
      "Thumb Marker Count: (209,)\tSize of Second: (21,1308)\n",
      "Thumb Marker Count: (209,)\tSize of Third: (21,1297)\n"
     ]
    }
   ],
   "source": [
    "## To Apply CSP, we first only get the indeces for MI tasks 1 and 2 (left and right hand, respectively.)\n",
    "tIdx = np.where(markerTargets == 1)[0]\n",
    "iIdx = np.where(markerTargets == 2)[0]\n",
    "mIdx = np.where(markerTargets == 3)[0]\n",
    "rIdx = np.where(markerTargets == 4)[0]\n",
    "pIdx = np.where(markerTargets == 5)[0]\n",
    "tCount = tIdx.shape\n",
    "print(\"Thumb Marker Count: {}\\tSize of First: ({},{})\".format(tCount, dataSplit[tIdx[0]].shape[0],dataSplit[tIdx[0]].shape[1]))\n",
    "print(\"Thumb Marker Count: {}\\tSize of Second: ({},{})\".format(tCount, dataSplit[tIdx[1]].shape[0],dataSplit[tIdx[1]].shape[1]))\n",
    "print(\"Thumb Marker Count: {}\\tSize of Third: ({},{})\".format(tCount, dataSplit[tIdx[2]].shape[0],dataSplit[tIdx[2]].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275\n"
     ]
    }
   ],
   "source": [
    "def GetMinSteps(indeces, data):\n",
    "    minVal = 9999;\n",
    "    for index in indeces:\n",
    "        length = data[index].shape[1];\n",
    "        if(length < minVal):\n",
    "            minVal = length;\n",
    "    return minVal\n",
    "\n",
    "tIdxMin = GetMinSteps(tIdx, dataSplit)\n",
    "iIdxMin = GetMinSteps(iIdx, dataSplit)\n",
    "mIdxMin = GetMinSteps(mIdx, dataSplit)\n",
    "rIdxMin = GetMinSteps(rIdx, dataSplit)\n",
    "pIdxMin = GetMinSteps(pIdx, dataSplit)\n",
    "minValues = [tIdxMin, iIdxMin, mIdxMin, rIdxMin, pIdxMin]\n",
    "minValues\n",
    "\n",
    "#Truncate the data to the min size\n",
    "minValue = np.min(minValues)\n",
    "print(minValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentData = dataSplit[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDataTrunc = currentData[:,0:1275]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 1275)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentDataTrunc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current index is: 11\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'currentData' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-b102fc96d5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataSplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0miData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataSplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataSplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-b102fc96d5c4>\u001b[0m in \u001b[0;36mGetData\u001b[0;34m(indeces, data, truncateValue)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current index is: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtruncateValue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'currentData' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def GetData(indeces, data, truncateValue):\n",
    "    data = []\n",
    "    truncate = True;\n",
    "    if truncateValue == 0:\n",
    "        truncate = False;\n",
    "    for idx in indeces:\n",
    "        try:\n",
    "            currentData = np.transpose(data[idx])\n",
    "            if truncate:\n",
    "                data.append(currentData[:,0:truncateValue])\n",
    "            else:\n",
    "                data.append(currentData)\n",
    "        except:\n",
    "            print(\"Current index is: {}\".format(idx))\n",
    "    return data\n",
    "\n",
    "tData = GetData(tIdx, dataSplit, minValue)\n",
    "iData = GetData(iIdx, dataSplit, minValue)\n",
    "mData = GetData(mIdx, dataSplit, minValue)\n",
    "rData = GetData(rIdx, dataSplit, minValue)\n",
    "pData = GetData(pIdx, dataSplit, minValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 170, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftData = [];\n",
    "for leftIndex in LeftIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[leftIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        leftData.append(np.transpose(dataSplit[leftIndex]))\n",
    "leftData = np.asarray(leftData)\n",
    "leftData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 170, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightData = [];\n",
    "for rightIndex in RightIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[rightIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        rightData.append(np.transpose(dataSplit[rightIndex]))\n",
    "rightData = np.asarray(rightData)\n",
    "rightData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep the top 288 samples, so that left and right data are equal\n",
    "rightDataSub = rightData[1:289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrData Shape: (576, 170, 22)\tmarkerTargets Shape: (576, 2)\n"
     ]
    }
   ],
   "source": [
    "#Construct the target array and merge the data\n",
    "leftTargets = np.tile(np.array([1,0]),(288,1))\n",
    "rightTargets = np.tile(np.array([0,1]), (288,1))\n",
    "markerTargets = np.vstack((leftTargets, rightTargets))\n",
    "lrData = np.vstack((leftData, rightDataSub))\n",
    "\n",
    "#Sanity Check\n",
    "print(\"lrData Shape: {arg1}\\tmarkerTargets Shape: {arg2}\".format(arg1=lrData.shape, arg2=markerTargets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle the data\n",
    "lrData, markerTargets = shuffle(lrData, markerTargets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "lrDataTrain, lrDataTest, markerTargetsTrain, markerTargetsTest = train_test_split(lrData, markerTargets, test_size=0.3, random_state=1)\n",
    "markerTargetsTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "lrDataTrainRe = lrDataTrain.reshape((lrDataTrain.shape[0], lrDataTrain.shape[1], lrDataTrain.shape[2]))\n",
    "lrDataTestRe = lrDataTest.reshape((lrDataTest.shape[0], lrDataTest.shape[1], lrDataTest.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the model\n",
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,lrDataTrainRe.shape[1], lrDataTrainRe.shape[2]), return_sequences=True))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "LSTM_EEG.add(Dense((2),activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 170, 100)          49200     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 79,502\n",
      "Trainable params: 79,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "26/26 - 5s - loss: 0.6775 - accuracy: 0.5980\n",
      "Epoch 2/30\n",
      "26/26 - 5s - loss: 0.6248 - accuracy: 0.6650\n",
      "Epoch 3/30\n",
      "26/26 - 4s - loss: 0.5491 - accuracy: 0.7146\n",
      "Epoch 4/30\n",
      "26/26 - 4s - loss: 0.5258 - accuracy: 0.7320\n",
      "Epoch 5/30\n",
      "26/26 - 4s - loss: 0.4521 - accuracy: 0.8238\n",
      "Epoch 6/30\n",
      "26/26 - 4s - loss: 0.4264 - accuracy: 0.7940\n",
      "Epoch 7/30\n",
      "26/26 - 4s - loss: 0.3616 - accuracy: 0.8437\n",
      "Epoch 8/30\n",
      "26/26 - 3s - loss: 0.3180 - accuracy: 0.8462\n",
      "Epoch 9/30\n",
      "26/26 - 3s - loss: 0.2930 - accuracy: 0.8883\n",
      "Epoch 10/30\n",
      "26/26 - 3s - loss: 0.2680 - accuracy: 0.8983\n",
      "Epoch 11/30\n",
      "26/26 - 3s - loss: 0.2678 - accuracy: 0.8983\n",
      "Epoch 12/30\n",
      "26/26 - 3s - loss: 0.2198 - accuracy: 0.9007\n",
      "Epoch 13/30\n",
      "26/26 - 4s - loss: 0.1466 - accuracy: 0.9454\n",
      "Epoch 14/30\n",
      "26/26 - 3s - loss: 0.1805 - accuracy: 0.9305\n",
      "Epoch 15/30\n",
      "26/26 - 2s - loss: 0.2859 - accuracy: 0.8759\n",
      "Epoch 16/30\n",
      "26/26 - 2s - loss: 0.2113 - accuracy: 0.9181\n",
      "Epoch 17/30\n",
      "26/26 - 2s - loss: 0.2795 - accuracy: 0.8834\n",
      "Epoch 18/30\n",
      "26/26 - 2s - loss: 0.1470 - accuracy: 0.9429\n",
      "Epoch 19/30\n",
      "26/26 - 2s - loss: 0.1164 - accuracy: 0.9529\n",
      "Epoch 20/30\n",
      "26/26 - 2s - loss: 0.0925 - accuracy: 0.9702\n",
      "Epoch 21/30\n",
      "26/26 - 2s - loss: 0.0356 - accuracy: 0.9926\n",
      "Epoch 22/30\n",
      "26/26 - 2s - loss: 0.0414 - accuracy: 0.9826\n",
      "Epoch 23/30\n",
      "26/26 - 2s - loss: 0.0428 - accuracy: 0.9826\n",
      "Epoch 24/30\n",
      "26/26 - 2s - loss: 0.1495 - accuracy: 0.9429\n",
      "Epoch 25/30\n",
      "26/26 - 2s - loss: 0.1657 - accuracy: 0.9305\n",
      "Epoch 26/30\n",
      "26/26 - 2s - loss: 0.0788 - accuracy: 0.9826\n",
      "Epoch 27/30\n",
      "26/26 - 2s - loss: 0.0367 - accuracy: 0.9901\n",
      "Epoch 28/30\n",
      "26/26 - 2s - loss: 0.0157 - accuracy: 0.9975\n",
      "Epoch 29/30\n",
      "26/26 - 2s - loss: 0.0363 - accuracy: 0.9926\n",
      "Epoch 30/30\n",
      "26/26 - 2s - loss: 0.0963 - accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "history = LSTM_EEG.fit(lrDataTrain, markerTargetsTrain, epochs=30,verbose=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest = LSTM_EEG.predict(lrDataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest>0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonArrayTest = predictionsTest == markerTargetsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = lrDataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(lrDataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = lrDataTrain.shape[0] - correctCountTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 384\n",
      "Incorrect MI Prediction: 19\n",
      "Percent Accuracy: 95.285%\n",
      "#################################\n",
      "#################################\n",
      "Test Performance:\n",
      "Correct MI Prediction: 110\n",
      "Incorrect MI Prediction: 63\n",
      "Percent Accuracy: 63.584%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, (correctCountTrain*100/lrDataTrain.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, (correctCountTest*100/lrDataTest.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
