{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 1 of 10\n",
      "Processing dataset 2 of 10\n",
      "Processing dataset 3 of 10\n",
      "Processing dataset 4 of 10\n",
      "Processing dataset 5 of 10\n",
      "Processing dataset 6 of 10\n",
      "Processing dataset 7 of 10\n",
      "Previous minValue: 1275\tCurrent minValue: 1274\n",
      "Pausing after iteration: 60\n",
      "Processing dataset 8 of 10\n",
      "Previous minValue: 1274\tCurrent minValue: 1276\n",
      "Pausing after iteration: 7\n",
      "Processing dataset 9 of 10\n",
      "Previous minValue: 1274\tCurrent minValue: 1309\n",
      "Pausing after iteration: 8\n",
      "Processing dataset 10 of 10\n",
      "Previous minValue: 1274\tCurrent minValue: 1275\n",
      "Pausing after iteration: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Documents/GitHub/ECE228ECGProject/JupyterNotebooks/helperFunctions.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return SFa.astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Import the helper functions\n",
    "#from helperFunctions import CSP\n",
    "from helperFunctions import GetCombinedData_5F\n",
    "\n",
    "\n",
    "enableDropout = True;\n",
    "dropoutPercentage = 0.3;\n",
    "\n",
    "#Run GetCombinedData to pull the datasets from multiple subjects into a single set\n",
    "Data, Targets, DataCSP, TargetsCSP = GetCombinedData_5F('../../../matDown/5F_Data', True);\n",
    "\n",
    "## Split into train and test sets\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(Data, Targets, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 21, 100)           550000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 580,455\n",
      "Trainable params: 580,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "372/372 - 13s - loss: 0.5106 - accuracy: 0.2250\n",
      "Epoch 2/30\n",
      "372/372 - 12s - loss: 0.4973 - accuracy: 0.2564\n",
      "Epoch 3/30\n",
      "372/372 - 10s - loss: 0.4921 - accuracy: 0.2763\n",
      "Epoch 4/30\n",
      "372/372 - 12s - loss: 0.4866 - accuracy: 0.3042\n",
      "Epoch 5/30\n",
      "372/372 - 11s - loss: 0.4846 - accuracy: 0.3131\n",
      "Epoch 6/30\n",
      "372/372 - 11s - loss: 0.4784 - accuracy: 0.3432\n",
      "Epoch 7/30\n",
      "372/372 - 12s - loss: 0.4730 - accuracy: 0.3477\n",
      "Epoch 8/30\n",
      "372/372 - 11s - loss: 0.4721 - accuracy: 0.3407\n",
      "Epoch 9/30\n",
      "372/372 - 12s - loss: 0.4674 - accuracy: 0.3646\n",
      "Epoch 10/30\n",
      "372/372 - 11s - loss: 0.4623 - accuracy: 0.3664\n",
      "Epoch 11/30\n",
      "372/372 - 11s - loss: 0.4589 - accuracy: 0.3857\n",
      "Epoch 12/30\n",
      "372/372 - 11s - loss: 0.4538 - accuracy: 0.4010\n",
      "Epoch 13/30\n",
      "372/372 - 11s - loss: 0.4535 - accuracy: 0.3945\n",
      "Epoch 14/30\n",
      "372/372 - 11s - loss: 0.4473 - accuracy: 0.4108\n",
      "Epoch 15/30\n",
      "372/372 - 11s - loss: 0.4417 - accuracy: 0.4256\n",
      "Epoch 16/30\n",
      "372/372 - 11s - loss: 0.4398 - accuracy: 0.4264\n",
      "Epoch 17/30\n",
      "372/372 - 11s - loss: 0.4383 - accuracy: 0.4362\n",
      "Epoch 18/30\n",
      "372/372 - 11s - loss: 0.4316 - accuracy: 0.4488\n",
      "Epoch 19/30\n",
      "372/372 - 11s - loss: 0.4308 - accuracy: 0.4453\n",
      "Epoch 20/30\n",
      "372/372 - 11s - loss: 0.4256 - accuracy: 0.4631\n",
      "Epoch 21/30\n",
      "372/372 - 11s - loss: 0.4222 - accuracy: 0.4685\n",
      "Epoch 22/30\n",
      "372/372 - 11s - loss: 0.4254 - accuracy: 0.4644\n",
      "Epoch 23/30\n",
      "372/372 - 11s - loss: 0.4233 - accuracy: 0.4691\n",
      "Epoch 24/30\n",
      "372/372 - 11s - loss: 0.4184 - accuracy: 0.4749\n",
      "Epoch 25/30\n",
      "372/372 - 11s - loss: 0.4155 - accuracy: 0.4833\n",
      "Epoch 26/30\n",
      "372/372 - 11s - loss: 0.4123 - accuracy: 0.4880\n",
      "Epoch 27/30\n",
      "372/372 - 11s - loss: 0.4112 - accuracy: 0.4903\n",
      "Epoch 28/30\n",
      "372/372 - 11s - loss: 0.4070 - accuracy: 0.4950\n",
      "Epoch 29/30\n",
      "372/372 - 11s - loss: 0.4051 - accuracy: 0.4966\n",
      "Epoch 30/30\n",
      "372/372 - 11s - loss: 0.4015 - accuracy: 0.5135\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 4312\n",
      "Incorrect MI Prediction: 1635\n",
      "Percent Accuracy: 72.507%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 1458\n",
      "Incorrect MI Prediction: 1091\n",
      "Percent Accuracy: 57.199%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Construct the model\n",
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,DataTrainRe.shape[1], DataTrainRe.shape[2]), return_sequences=True))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(Dense((5),activation='sigmoid'))\n",
    "\n",
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results without CSP\n",
    "\n",
    "### Training Performance:\n",
    "Correct MI Prediction: 4312\n",
    "\n",
    "Incorrect MI Prediction: 1635\n",
    "\n",
    "Percent Accuracy: 72.507%\n",
    "#################################\n",
    "\n",
    "\n",
    "### Testing Performance:\n",
    "Correct MI Prediction: 1458\n",
    "\n",
    "Incorrect MI Prediction: 1091\n",
    "\n",
    "Percent Accuracy: 57.199%\n",
    "#################################\n",
    "\n",
    "\n",
    "We can see that training the LSTM on the combined data reduces overfitting but still provides only mediocre test results.\n",
    "\n",
    "In the next cell, we train the same model on the CSP data, which has already been generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "372/372 - 11s - loss: 0.4980 - accuracy: 0.2817\n",
      "Epoch 2/30\n",
      "372/372 - 17s - loss: 0.4722 - accuracy: 0.3493\n",
      "Epoch 3/30\n",
      "372/372 - 11s - loss: 0.4593 - accuracy: 0.3871\n",
      "Epoch 4/30\n",
      "372/372 - 10s - loss: 0.4491 - accuracy: 0.4246\n",
      "Epoch 5/30\n",
      "372/372 - 11s - loss: 0.4340 - accuracy: 0.4549\n",
      "Epoch 6/30\n",
      "372/372 - 11s - loss: 0.4155 - accuracy: 0.5023\n",
      "Epoch 7/30\n",
      "372/372 - 11s - loss: 0.3995 - accuracy: 0.5243\n",
      "Epoch 8/30\n",
      "372/372 - 11s - loss: 0.3889 - accuracy: 0.5391\n",
      "Epoch 9/30\n",
      "372/372 - 11s - loss: 0.3758 - accuracy: 0.5568\n",
      "Epoch 10/30\n",
      "372/372 - 11s - loss: 0.3646 - accuracy: 0.5697\n",
      "Epoch 11/30\n",
      "372/372 - 11s - loss: 0.3557 - accuracy: 0.5811\n",
      "Epoch 12/30\n",
      "372/372 - 12s - loss: 0.3503 - accuracy: 0.5944\n",
      "Epoch 13/30\n",
      "372/372 - 12s - loss: 0.3515 - accuracy: 0.5867\n",
      "Epoch 14/30\n",
      "372/372 - 12s - loss: 0.3467 - accuracy: 0.5914\n",
      "Epoch 15/30\n",
      "372/372 - 12s - loss: 0.3286 - accuracy: 0.6279\n",
      "Epoch 16/30\n",
      "372/372 - 12s - loss: 0.3281 - accuracy: 0.6225\n",
      "Epoch 17/30\n",
      "372/372 - 12s - loss: 0.3159 - accuracy: 0.6445\n",
      "Epoch 18/30\n",
      "372/372 - 12s - loss: 0.3142 - accuracy: 0.6459\n",
      "Epoch 19/30\n",
      "372/372 - 12s - loss: 0.3086 - accuracy: 0.6482\n",
      "Epoch 20/30\n",
      "372/372 - 11s - loss: 0.3007 - accuracy: 0.6608\n",
      "Epoch 21/30\n",
      "372/372 - 11s - loss: 0.3023 - accuracy: 0.6496\n",
      "Epoch 22/30\n",
      "372/372 - 11s - loss: 0.2888 - accuracy: 0.6782\n",
      "Epoch 23/30\n",
      "372/372 - 11s - loss: 0.2772 - accuracy: 0.6965\n",
      "Epoch 24/30\n",
      "372/372 - 11s - loss: 0.2757 - accuracy: 0.6972\n",
      "Epoch 25/30\n",
      "372/372 - 11s - loss: 0.2721 - accuracy: 0.7039\n",
      "Epoch 26/30\n",
      "372/372 - 12s - loss: 0.2630 - accuracy: 0.7150\n",
      "Epoch 27/30\n",
      "372/372 - 12s - loss: 0.2551 - accuracy: 0.7252\n",
      "Epoch 28/30\n",
      "372/372 - 11s - loss: 0.2571 - accuracy: 0.7204\n",
      "Epoch 29/30\n",
      "372/372 - 11s - loss: 0.2526 - accuracy: 0.7246\n",
      "Epoch 30/30\n",
      "372/372 - 11s - loss: 0.2466 - accuracy: 0.7330\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 5062\n",
      "Incorrect MI Prediction: 885\n",
      "Percent Accuracy: 85.119%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 2090\n",
      "Incorrect MI Prediction: 459\n",
      "Percent Accuracy: 81.993%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(DataCSP, TargetsCSP, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results with CSP\n",
    "---\n",
    "### Training Performance:\n",
    "Correct MI Prediction: 5062\n",
    "    \n",
    "Incorrect MI Prediction: 885\n",
    "    \n",
    "Percent Accuracy: 85.119%\n",
    "\n",
    "---\n",
    "\n",
    "### Testing Performance:\n",
    "Testing Performance:\n",
    "    \n",
    "Correct MI Prediction: 2090\n",
    "    \n",
    "Incorrect MI Prediction: 459\n",
    "    \n",
    "Percent Accuracy: 81.993%\n",
    "\n",
    "---\n",
    "We see that CSP greatly increases the accuracy for both the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97.14285714, 94.7107438 , 96.63865546, 94.7107438 , 97.68595041,\n",
       "        86.12521151, 88.09917355, 85.95890411, 91.86046512, 81.15702479]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyNoCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98.48739496, 91.90082645, 97.14285714, 87.27272727, 92.56198347,\n",
       "        96.27749577, 98.34710744, 74.14383562, 87.20930233, 81.65289256]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyWithCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedArray = np.transpose(np.asarray(np.vstack((trainAccuracyNoCSP,testAccuracyNoCSP,trainAccuracyWithCSP, testAccuracyWithCSP))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('5FperSubject_Dropout.csv', combinedArray, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davalenc/ProjectFiles/ECE228ECGProject/JupyterNotebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((3,2,3))+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[:, :, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5., 5.],\n",
       "        [5., 5.]],\n",
       "\n",
       "       [[5., 5.],\n",
       "        [5., 5.]],\n",
       "\n",
       "       [[5., 5.],\n",
       "        [5., 5.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
