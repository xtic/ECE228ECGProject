{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two-Class EEG Classification using LSTM-based RNN\n",
    "## Here, we develop a baseline model for using an RNN to perform time-series prediction for one of two motor\n",
    "## imagery (MI) tasks. The data from the file CLA_SubjectJ-170508-3St-LRHand-Inter.mat is processed and we\n",
    "## only keep the data points that pertain to the left and right hand MI tasks. Each of the MI task data consists\n",
    "## of 170 time steps, with each time step consisting of 22 inputs. In other words, we pass the current sample for\n",
    "## of the 22 channels for each time step. At the end of the 170 time step, we send the output of the LSTM layers\n",
    "## to a Dense layer with two outputs. To ease the classification at the outer layer, we have converted the class\n",
    "## into a one-hot encoding of zeros and ones, and use the sigmoid unit at the output to match the output range.\n",
    "\n",
    "## Preliminary results:\n",
    "## Performance on training set is 100% classification rate after around 30 to 40 epochs.\n",
    "## Performance on test set is around 60% - 68%.\n",
    "\n",
    "## Potential problems:\n",
    "## The total amount of data is relatively low. Can it be possible to combine multiple subject's L/R Hand MI data\n",
    "## into one unified data set?\n",
    "## Can also possible increase the size of the data set by doing some data augmentations.\n",
    "## For example, injecting some noise into the existing EEG data to create more test data?\n",
    "\n",
    "## Followup/TODO:\n",
    "## Use pre-implemented common spatial patterns for feature extraction: avialable here: https://github.com/spolsley/common-spatial-patterns\n",
    "## Try using a relatively simple non-linear energy operator as a pre-emphasis step on the data to see if it helps generalize\n",
    "## the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-18.   -3.6  -6.6 ...  -9.   -7.2  -2.4]\n",
      " [-19.2  -0.   -8.4 ...  -8.4 -11.4  -9. ]\n",
      " [-12.    1.8  -1.2 ...   2.4   3.6   5.4]\n",
      " ...\n",
      " [ -7.2   7.2   1.8 ...   1.8   4.2   4.2]\n",
      " [ -6.    5.4   3.  ...   5.4   4.2   3.6]\n",
      " [ -8.4   7.2   3.  ...   4.8   6.6   6. ]]\n",
      "Number of samples: 621892\n",
      "Dataset ID: 201705081338.32BEA9DD\n",
      "Channel names: [array(['Fp1'], dtype='<U3') array(['Fp2'], dtype='<U3')\n",
      " array(['F3'], dtype='<U2') array(['F4'], dtype='<U2')\n",
      " array(['C3'], dtype='<U2') array(['C4'], dtype='<U2')\n",
      " array(['P3'], dtype='<U2') array(['P4'], dtype='<U2')\n",
      " array(['O1'], dtype='<U2') array(['O2'], dtype='<U2')\n",
      " array(['A1'], dtype='<U2') array(['A2'], dtype='<U2')\n",
      " array(['F7'], dtype='<U2') array(['F8'], dtype='<U2')\n",
      " array(['T3'], dtype='<U2') array(['T4'], dtype='<U2')\n",
      " array(['T5'], dtype='<U2') array(['T6'], dtype='<U2')\n",
      " array(['Fz'], dtype='<U2') array(['Cz'], dtype='<U2')\n",
      " array(['Pz'], dtype='<U2')]\n"
     ]
    }
   ],
   "source": [
    "## This file is used to split data into series of arrays and their corresponding MI task.\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "file = sio.loadmat('../../../matDown/CLA_Data/CLA-SubjectJ-170508-3St-LRHand-Inter.mat') #replace with .mat file name\n",
    "header=file['__header__']\n",
    "version=file['__version__']\n",
    "glob=file['__globals__']\n",
    "ans=file['ans']\n",
    "\n",
    "\n",
    "x=file['x']\n",
    "o=file['o'][0][0]\n",
    "data=o['data']\n",
    "data = np.transpose(data)\n",
    "data = data[0:21,:]\n",
    "print(data)\n",
    "nS=o['nS'][0][0]\n",
    "#values of structure seem to be 2D numpy arrays, if originally a scalar in Matlab.\n",
    "#use [0][0] to get scalar.\n",
    "print(\"Number of samples: {numSamples}\".format(numSamples=nS))\n",
    "test=o['id'][0] #id value became a 1D array of size 1 for some reason. use [0] to get value\n",
    "print(\"Dataset ID: {id}\".format(id=test))\n",
    "chnames=o['chnames'][:,0] #[:,0] converts from 2D array back to 1D array\n",
    "print(\"Channel names: {channelNames}\".format(channelNames=chnames))\n",
    "markers = o['marker']\n",
    "## The markers are all still individual arrays of size 1x1, so we convert them to an array with single values\n",
    "markersArray = []\n",
    "for marker in markers:\n",
    "    markersArray.append(marker[0])\n",
    "markersArray = np.asarray(markersArray)\n",
    "#For this dataset, the markers are 0, 1, or 2.\n",
    "# 1 - Left Hand MI, 2 - Right Hand MI, 3 - Passive State, 0 - Rest (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSP File from: https://github.com/spolsley/common-spatial-patterns\n",
    "# CSP takes any number of arguments, but each argument must be a collection of trials associated with a task\n",
    "# That is, for N tasks, N arrays are passed to CSP each with dimensionality (# of trials of task N) x (feature vector)\n",
    "# Trials may be of any dimension, provided that each trial for each task has the same dimensionality,\n",
    "# otherwise there can be no spatial filtering since the trials cannot be compared\n",
    "def CSP(*tasks):\n",
    "\tif len(tasks) < 2:\n",
    "\t\tprint(\"Must have at least 2 tasks for filtering.\")\n",
    "\t\treturn (None,) * len(tasks)\n",
    "\telse:\n",
    "\t\tfilters = ()\n",
    "\t\t# CSP algorithm\n",
    "\t\t# For each task x, find the mean variances Rx and not_Rx, which will be used to compute spatial filter SFx\n",
    "\t\titerator = range(0,len(tasks))\n",
    "\t\tfor x in iterator:\n",
    "\t\t\t# Find Rx\n",
    "\t\t\tRx = covarianceMatrix(tasks[x][0])\n",
    "\t\t\tfor t in range(1,len(tasks[x])):\n",
    "\t\t\t\tRx += covarianceMatrix(tasks[x][t])\n",
    "\t\t\tRx = Rx / len(tasks[x])\n",
    "\n",
    "\t\t\t# Find not_Rx\n",
    "\t\t\tcount = 0\n",
    "\t\t\tnot_Rx = Rx * 0\n",
    "\t\t\tfor not_x in [element for element in iterator if element != x]:\n",
    "\t\t\t\tfor t in range(0,len(tasks[not_x])):\n",
    "\t\t\t\t\tnot_Rx += covarianceMatrix(tasks[not_x][t])\n",
    "\t\t\t\t\tcount += 1\n",
    "\t\t\tnot_Rx = not_Rx / count\n",
    "\n",
    "\t\t\t# Find the spatial filter SFx\n",
    "\t\t\tSFx = spatialFilter(Rx,not_Rx)\n",
    "\t\t\tfilters += (SFx,)\n",
    "\n",
    "\t\t\t# Special case: only two tasks, no need to compute any more mean variances\n",
    "\t\t\tif len(tasks) == 2:\n",
    "\t\t\t\tfilters += (spatialFilter(not_Rx,Rx),)\n",
    "\t\t\t\tbreak\n",
    "\t\treturn filters\n",
    "\n",
    "# covarianceMatrix takes a matrix A and returns the covariance matrix, scaled by the variance\n",
    "def covarianceMatrix(A):\n",
    "\tCa = np.dot(A,np.transpose(A))/np.trace(np.dot(A,np.transpose(A)))\n",
    "\treturn Ca\n",
    "\n",
    "# spatialFilter returns the spatial filter SFa for mean covariance matrices Ra and Rb\n",
    "def spatialFilter(Ra,Rb):\n",
    "\tR = Ra + Rb\n",
    "\tE,U = la.eig(R)\n",
    "\n",
    "\t# CSP requires the eigenvalues E and eigenvector U be sorted in descending order\n",
    "\tord = np.argsort(E)\n",
    "\tord = ord[::-1] # argsort gives ascending order, flip to get descending\n",
    "\tE = E[ord]\n",
    "\tU = U[:,ord]\n",
    "\n",
    "\t# Find the whitening transformation matrix\n",
    "\tP = np.dot(np.sqrt(la.inv(np.diag(E))),np.transpose(U))\n",
    "\n",
    "\t# The mean covariance matrices may now be transformed\n",
    "\tSa = np.dot(P,np.dot(Ra,np.transpose(P)))\n",
    "\tSb = np.dot(P,np.dot(Rb,np.transpose(P)))\n",
    "\n",
    "\t# Find and sort the generalized eigenvalues and eigenvector\n",
    "\tE1,U1 = la.eig(Sa,Sb)\n",
    "\tord1 = np.argsort(E1)\n",
    "\tord1 = ord1[::-1]\n",
    "\tE1 = E1[ord1]\n",
    "\tU1 = U1[:,ord1]\n",
    "\n",
    "\t# The projection matrix (the spatial filter) may now be obtained\n",
    "\tSFa = np.dot(np.transpose(U1),P)\n",
    "\treturn SFa.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of index changes: 1800\n",
      "Number of arrays in data split: 1800\n",
      "Number of marker targets: 1800\n"
     ]
    }
   ],
   "source": [
    "## Find the starting indeces where the marker changes\n",
    "changeIdxs = np.where(np.transpose(markersArray)[:-1] != np.transpose(markersArray)[1:])[0]\n",
    "print(\"Number of index changes: {idxChanges}\".format(idxChanges=changeIdxs.shape[0]))\n",
    "## Split the data so that it has its matching marker\n",
    "dataSplit = np.array_split(data, changeIdxs[:-1], axis=1)\n",
    "splitCount = 0\n",
    "for splitData in dataSplit:\n",
    "    splitCount += 1\n",
    "print(\"Number of arrays in data split: {num}\".format(num=splitCount))\n",
    "## Retrieve the marker values for each of the change indeces (changeIdxs)\n",
    "markerTargets = markersArray[changeIdxs];\n",
    "print(\"Number of marker targets: {numTargets}\".format(numTargets=markerTargets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Apply CSP, we first only get the indeces for MI tasks 1 and 2 (left and right hand, respectively.)\n",
    "LeftIdxs = np.where(markerTargets == 1)\n",
    "RightIdxs = np.where(markerTargets == 2)\n",
    "NoneIdxs = np.where(markerTargets == 3)\n",
    "numLeftIdx = LeftIdxs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 170, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftData = [];\n",
    "for leftIndex in LeftIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[leftIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        leftData.append(np.transpose(dataSplit[leftIndex]))\n",
    "leftData = np.asarray(leftData)\n",
    "leftData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 170, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightData = [];\n",
    "for rightIndex in RightIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[rightIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        rightData.append(np.transpose(dataSplit[rightIndex]))\n",
    "rightData = np.asarray(rightData)\n",
    "rightData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 170, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noneData=[]\n",
    "for noneIndex in NoneIdxs[0]:\n",
    "    if(dataSplit[noneIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        noneData.append(np.transpose(dataSplit[noneIndex]))\n",
    "noneData=np.asarray(noneData)\n",
    "noneData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep the top 288 samples, so that left and right data are equal #why start at index 1?\n",
    "keep=284;\n",
    "rightDataSub = rightData[1:(keep+1)]\n",
    "leftDataSub = leftData[1:(keep+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrData Shape: (852, 170, 21)\tmarkerTargets Shape: (852, 3)\n"
     ]
    }
   ],
   "source": [
    "#Construct the target array and merge the data\n",
    "leftTargets = np.tile(np.array([1,0, 0]),(keep,1))\n",
    "rightTargets = np.tile(np.array([0, 0,1]), (keep,1))\n",
    "noneTargets = np.tile(np.array([0, 1, 0]), (keep,1))\n",
    "markerTargets = np.vstack((leftTargets, noneTargets, rightTargets))\n",
    "lrData = np.vstack((leftDataSub, noneData, rightDataSub))\n",
    "\n",
    "#Sanity Check\n",
    "print(\"lrData Shape: {arg1}\\tmarkerTargets Shape: {arg2}\".format(arg1=lrData.shape, arg2=markerTargets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle the data\n",
    "lrData, markerTargets = shuffle(lrData, markerTargets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "lrDataTrain, lrDataTest, markerTargetsTrain, markerTargetsTest = train_test_split(lrData, markerTargets, test_size=0.3, random_state=1)\n",
    "markerTargetsTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "lrDataTrainRe = lrDataTrain.reshape((lrDataTrain.shape[0], lrDataTrain.shape[1], lrDataTrain.shape[2]))\n",
    "lrDataTestRe = lrDataTest.reshape((lrDataTest.shape[0], lrDataTest.shape[1], lrDataTest.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the model\n",
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,lrDataTrainRe.shape[1], lrDataTrainRe.shape[2]), return_sequences=True))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "LSTM_EEG.add(Dense((3),activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 170, 100)          48800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 79,153\n",
      "Trainable params: 79,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 - 3s - loss: 1.0487 - accuracy: 0.4508 - val_loss: 0.9963 - val_accuracy: 0.4860\n",
      "Epoch 2/100\n",
      "27/27 - 3s - loss: 0.9377 - accuracy: 0.5635 - val_loss: 0.9588 - val_accuracy: 0.5419\n",
      "Epoch 3/100\n",
      "27/27 - 3s - loss: 0.8065 - accuracy: 0.6307 - val_loss: 0.9201 - val_accuracy: 0.5587\n",
      "Epoch 4/100\n",
      "27/27 - 3s - loss: 0.7442 - accuracy: 0.6859 - val_loss: 1.0920 - val_accuracy: 0.4637\n",
      "Epoch 5/100\n",
      "27/27 - 3s - loss: 0.7557 - accuracy: 0.6571 - val_loss: 0.9450 - val_accuracy: 0.5307\n",
      "Epoch 6/100\n",
      "27/27 - 3s - loss: 0.6752 - accuracy: 0.6906 - val_loss: 0.9299 - val_accuracy: 0.5307\n",
      "Epoch 7/100\n",
      "27/27 - 3s - loss: 0.6107 - accuracy: 0.7266 - val_loss: 1.0264 - val_accuracy: 0.5866\n",
      "Epoch 8/100\n",
      "27/27 - 3s - loss: 0.6437 - accuracy: 0.7146 - val_loss: 1.0262 - val_accuracy: 0.5419\n",
      "Epoch 9/100\n",
      "27/27 - 3s - loss: 0.6716 - accuracy: 0.6978 - val_loss: 1.1304 - val_accuracy: 0.5587\n",
      "Epoch 10/100\n",
      "27/27 - 3s - loss: 0.5464 - accuracy: 0.7770 - val_loss: 1.0778 - val_accuracy: 0.6034\n",
      "Epoch 11/100\n",
      "27/27 - 3s - loss: 0.4150 - accuracy: 0.8489 - val_loss: 1.1915 - val_accuracy: 0.5363\n",
      "Epoch 12/100\n",
      "27/27 - 3s - loss: 0.3923 - accuracy: 0.8297 - val_loss: 1.1872 - val_accuracy: 0.5251\n",
      "Epoch 13/100\n",
      "27/27 - 3s - loss: 0.5057 - accuracy: 0.7794 - val_loss: 1.2491 - val_accuracy: 0.5196\n",
      "Epoch 14/100\n",
      "27/27 - 3s - loss: 0.4260 - accuracy: 0.8058 - val_loss: 1.2798 - val_accuracy: 0.5363\n",
      "Epoch 15/100\n",
      "27/27 - 3s - loss: 0.4327 - accuracy: 0.8369 - val_loss: 1.6014 - val_accuracy: 0.4469\n",
      "Epoch 16/100\n",
      "27/27 - 5s - loss: 0.4623 - accuracy: 0.8177 - val_loss: 1.3574 - val_accuracy: 0.5810\n",
      "Epoch 17/100\n",
      "27/27 - 4s - loss: 0.3657 - accuracy: 0.8489 - val_loss: 1.5713 - val_accuracy: 0.4860\n",
      "Epoch 18/100\n",
      "27/27 - 3s - loss: 0.4856 - accuracy: 0.8106 - val_loss: 1.3176 - val_accuracy: 0.5307\n",
      "Epoch 19/100\n",
      "27/27 - 3s - loss: 0.2919 - accuracy: 0.8897 - val_loss: 1.3341 - val_accuracy: 0.5698\n",
      "Epoch 20/100\n",
      "27/27 - 3s - loss: 0.2375 - accuracy: 0.9137 - val_loss: 1.5154 - val_accuracy: 0.4916\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a7841a58c1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_EEG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrDataTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkerTargetsTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = LSTM_EEG.fit(lrDataTrain, markerTargetsTrain, validation_split=.3, epochs=100,verbose=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3067d1a439a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest = LSTM_EEG.predict(lrDataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest>0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonArrayTest = predictionsTest == markerTargetsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = lrDataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(lrDataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1] & boolValues[2]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = lrDataTrain.shape[0] - correctCountTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 391\n",
      "Incorrect MI Prediction: 205\n",
      "Percent Accuracy: 65.604%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 129\n",
      "Incorrect MI Prediction: 127\n",
      "Percent Accuracy: 50.391%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, (correctCountTrain*100/lrDataTrain.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, (correctCountTest*100/lrDataTest.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 170)\n",
      "(2, 170)\n",
      "(2, 170)\n"
     ]
    }
   ],
   "source": [
    "## Applying CSP on the data.\n",
    "## Test applying CSP on the first channel\n",
    "exampleLeft = np.transpose(leftData[0])[0:2]\n",
    "exampleRight = np.transpose(rightData[0])[0:2]\n",
    "exampleNone = np.transpose(noneData[0])[0:2]\n",
    "print(exampleLeft.shape)\n",
    "print(exampleRight.shape)\n",
    "print(exampleNone.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:73: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "#Send these two to CSP\n",
    "filters = CSP(leftDataSub, noneData, rightDataSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersArray = np.asarray(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 170, 170)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtersArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = filtersArray[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter2 = filtersArray[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter3 = filtersArray[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftData_CSP = np.matmul(np.transpose(filter1), leftDataSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightData_CSP = np.matmul(np.transpose(filter3), rightDataSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "noneData_CSP = np.matmul(np.transpose(filter2), noneData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrData_CSP Shape: (852, 170, 21)\tmarkerTargets_CSP Shape: (852, 3)\n"
     ]
    }
   ],
   "source": [
    "#Construct the target array and merge the data\n",
    "leftTargets_CSP = np.tile(np.array([1,0,0]),(keep,1))\n",
    "rightTargets_CSP = np.tile(np.array([0,0,1]), (keep,1))\n",
    "noneTargets_CSP = np.tile(np.array([0,1,0]), (keep,1))\n",
    "markerTargets_CSP = np.vstack((leftTargets_CSP, noneTargets_CSP, rightTargets_CSP))\n",
    "lrData_CSP = np.vstack((leftData_CSP, noneData_CSP, rightData_CSP))\n",
    "\n",
    "#Sanity Check\n",
    "print(\"lrData_CSP Shape: {arg1}\\tmarkerTargets_CSP Shape: {arg2}\".format(arg1=lrData_CSP.shape, arg2=markerTargets_CSP.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle the data\n",
    "lrData_CSP, markerTargets_CSP = shuffle(lrData_CSP, markerTargets_CSP, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "lrDataTrain_CSP, lrDataTest_CSP, markerTargetsTrain_CSP, markerTargetsTest_CSP = train_test_split(lrData_CSP, markerTargets_CSP, test_size=0.3, random_state=1)\n",
    "markerTargetsTrain_CSP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "lrDataTrainRe_CSP = lrDataTrain_CSP.reshape((lrDataTrain_CSP.shape[0], lrDataTrain_CSP.shape[1], lrDataTrain_CSP.shape[2]))\n",
    "lrDataTestRe_CSP = lrDataTest_CSP.reshape((lrDataTest_CSP.shape[0], lrDataTest_CSP.shape[1], lrDataTest_CSP.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the model\n",
    "LSTM_EEG_CSP = Sequential()\n",
    "LSTM_EEG_CSP.add(LSTM((100),batch_input_shape=(None,lrDataTrainRe_CSP.shape[1], lrDataTrainRe_CSP.shape[2]), return_sequences=True))\n",
    "LSTM_EEG_CSP.add(LSTM((50), return_sequences=False))\n",
    "LSTM_EEG_CSP.add(Dense((3),activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 170, 100)          48800     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 79,153\n",
      "Trainable params: 79,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_EEG_CSP.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG_CSP.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 - 3s - loss: 1.0772 - accuracy: 0.4101 - val_loss: 1.0310 - val_accuracy: 0.5028\n",
      "Epoch 2/20\n",
      "27/27 - 3s - loss: 0.9995 - accuracy: 0.5084 - val_loss: 1.0794 - val_accuracy: 0.4190\n",
      "Epoch 3/20\n",
      "27/27 - 3s - loss: 0.9552 - accuracy: 0.5707 - val_loss: 0.9097 - val_accuracy: 0.6257\n",
      "Epoch 4/20\n",
      "27/27 - 3s - loss: 0.8743 - accuracy: 0.6331 - val_loss: 0.9917 - val_accuracy: 0.5251\n",
      "Epoch 5/20\n",
      "27/27 - 3s - loss: 0.8616 - accuracy: 0.6283 - val_loss: 0.9839 - val_accuracy: 0.5531\n",
      "Epoch 6/20\n",
      "27/27 - 3s - loss: 0.7680 - accuracy: 0.6739 - val_loss: 1.0016 - val_accuracy: 0.5922\n",
      "Epoch 7/20\n",
      "27/27 - 4s - loss: 0.7712 - accuracy: 0.6954 - val_loss: 0.9912 - val_accuracy: 0.5587\n",
      "Epoch 8/20\n",
      "27/27 - 4s - loss: 0.6914 - accuracy: 0.7218 - val_loss: 0.8215 - val_accuracy: 0.6592\n",
      "Epoch 9/20\n",
      "27/27 - 3s - loss: 0.7138 - accuracy: 0.6978 - val_loss: 0.8160 - val_accuracy: 0.6704\n",
      "Epoch 10/20\n",
      "27/27 - 3s - loss: 0.6664 - accuracy: 0.7266 - val_loss: 0.7999 - val_accuracy: 0.6592\n",
      "Epoch 11/20\n",
      "27/27 - 3s - loss: 0.6273 - accuracy: 0.7818 - val_loss: 1.0140 - val_accuracy: 0.5754\n",
      "Epoch 12/20\n",
      "27/27 - 3s - loss: 0.6426 - accuracy: 0.7410 - val_loss: 0.9182 - val_accuracy: 0.6592\n",
      "Epoch 13/20\n",
      "27/27 - 3s - loss: 0.5479 - accuracy: 0.7722 - val_loss: 0.9447 - val_accuracy: 0.6369\n",
      "Epoch 14/20\n",
      "27/27 - 3s - loss: 0.5266 - accuracy: 0.8058 - val_loss: 1.0874 - val_accuracy: 0.5810\n",
      "Epoch 15/20\n",
      "27/27 - 3s - loss: 0.5112 - accuracy: 0.8034 - val_loss: 1.1228 - val_accuracy: 0.6089\n",
      "Epoch 16/20\n",
      "27/27 - 3s - loss: 0.4841 - accuracy: 0.8010 - val_loss: 0.8576 - val_accuracy: 0.6425\n",
      "Epoch 17/20\n",
      "27/27 - 3s - loss: 0.5160 - accuracy: 0.7986 - val_loss: 1.0214 - val_accuracy: 0.6034\n",
      "Epoch 18/20\n",
      "27/27 - 3s - loss: 0.4949 - accuracy: 0.7842 - val_loss: 0.9398 - val_accuracy: 0.6313\n",
      "Epoch 19/20\n",
      "27/27 - 3s - loss: 0.4765 - accuracy: 0.8010 - val_loss: 0.8522 - val_accuracy: 0.6872\n",
      "Epoch 20/20\n",
      "27/27 - 3s - loss: 0.3508 - accuracy: 0.8657 - val_loss: 0.9193 - val_accuracy: 0.6983\n"
     ]
    }
   ],
   "source": [
    "history_CSP = LSTM_EEG_CSP.fit(lrDataTrain_CSP, markerTargetsTrain_CSP, epochs=20,verbose=2, batch_size=16, validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest_CSP = LSTM_EEG_CSP.predict(lrDataTest_CSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest_CSP[predictionsTest_CSP>0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest_CSP[predictionsTest_CSP <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonArrayTest_CSP = predictionsTest_CSP == markerTargetsTest_CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest_CSP:\n",
    "    if(boolValues[0] & boolValues[1] & boolValues[2]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = lrDataTest_CSP.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG_CSP.predict(lrDataTrain_CSP)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = lrDataTrain_CSP.shape[0] - correctCountTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "### RESULTS AFTER APPLYING CSP ##\n",
      "#################################\n",
      "#################################\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 276\n",
      "Incorrect MI Prediction: 320\n",
      "Percent Accuracy: 46.309%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 43\n",
      "Incorrect MI Prediction: 213\n",
      "Percent Accuracy: 16.797%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"### RESULTS AFTER APPLYING CSP ##\")\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, (correctCountTrain*100/lrDataTrain.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, (correctCountTest*100/lrDataTest.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
