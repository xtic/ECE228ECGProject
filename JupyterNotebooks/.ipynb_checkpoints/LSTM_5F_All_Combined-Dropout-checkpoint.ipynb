{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 1 of 10\n",
      "Processing dataset 2 of 10\n",
      "Processing dataset 3 of 10\n",
      "Processing dataset 4 of 10\n",
      "Processing dataset 5 of 10\n",
      "Processing dataset 6 of 10\n",
      "Processing dataset 7 of 10\n",
      "Processing dataset 8 of 10\n",
      "Processing dataset 9 of 10\n",
      "Processing dataset 10 of 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shuffle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0c177bcddd12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#Run GetCombinedData to pull the datasets from multiple subjects into a single set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetCombinedData_5F\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../matDown/5F_Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m## Split into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ECE228ECGProject/JupyterNotebooks/helperFunctions.py\u001b[0m in \u001b[0;36mGetCombinedData_5F\u001b[0;34m(relativeFilePath, shuffleData, enableCSP)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffleData\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shuffle' is not defined"
     ]
    }
   ],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Import the helper functions\n",
    "#from helperFunctions import CSP\n",
    "from helperFunctions import GetCombinedData_5F\n",
    "\n",
    "\n",
    "enableDropout = True;\n",
    "dropoutPercentage = 0.3;\n",
    "\n",
    "#Run GetCombinedData to pull the datasets from multiple subjects into a single set\n",
    "Data, Targets = GetCombinedData_5F('../../../matDown/5F_Data', True);\n",
    "\n",
    "## Split into train and test sets\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(Data, Targets, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataTrainRe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5f9e546bb703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Construct the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mLSTM_EEG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mLSTM_EEG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataTrainRe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTrainRe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menableDropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mLSTM_EEG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropoutPercentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataTrainRe' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## Construct the model\n",
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,DataTrainRe.shape[1], DataTrainRe.shape[2]), return_sequences=True))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(Dense((5),activation='sigmoid'))\n",
    "\n",
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = LSTM_EEG.fit(FingerDataTrain, markerTargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "#Save these values into the array\n",
    "trainAccuracyNoCSP[0,dataset] = trainAcc_noCSP;\n",
    "testAccuracyNoCSP[0, dataset] = testAcc_noCSP;\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5F-SubjectB-160309-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectB-160311-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectC-160429-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectE-160321-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectF-160210-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectG-160413-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectG-160428-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectH-160804-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectI-160719-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectI-160723-5St-SGLHand-HFREQ.mat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50.19607843, 53.07692308, 55.29411765, 46.15384615, 40.76923077,\n",
       "        61.02362205, 51.53846154, 52.19123506, 51.5503876 , 58.84615385]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAccuracyNoCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85.49019608, 79.61538462, 85.09803922, 66.53846154, 61.15384615,\n",
       "        90.5511811 , 89.61538462, 58.96414343, 68.60465116, 73.84615385]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAccuracyWithCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97.14285714, 94.7107438 , 96.63865546, 94.7107438 , 97.68595041,\n",
       "        86.12521151, 88.09917355, 85.95890411, 91.86046512, 81.15702479]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyNoCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98.48739496, 91.90082645, 97.14285714, 87.27272727, 92.56198347,\n",
       "        96.27749577, 98.34710744, 74.14383562, 87.20930233, 81.65289256]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyWithCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedArray = np.transpose(np.asarray(np.vstack((trainAccuracyNoCSP,testAccuracyNoCSP,trainAccuracyWithCSP, testAccuracyWithCSP))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('5FperSubject_Dropout.csv', combinedArray, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davalenc/ProjectFiles/ECE228ECGProject/JupyterNotebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
