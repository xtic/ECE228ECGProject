{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available paradigms:\n",
      "Hand, Leg, Tongue (HALT)\n",
      "Classic - L/R Hand (CLA)\n",
      "Fingers (5F)\n",
      "Enter desired paradigm: 5F\n",
      "Enter the relative path to data: ../../../matDown/5F_Data/\n",
      "Processing dataset 1 of 10\n",
      "Processing dataset 2 of 10\n",
      "Processing dataset 3 of 10\n",
      "Processing dataset 4 of 10\n",
      "Processing dataset 5 of 10\n",
      "Processing dataset 6 of 10\n",
      "Processing dataset 7 of 10\n",
      "Processing dataset 8 of 10\n",
      "Processing dataset 9 of 10\n",
      "Processing dataset 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Documents/GitHub/ECE228ECGProject/JupyterNotebooks/helperFunctions.py:87: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return SFa.astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Import the helper functions\n",
    "#from helperFunctions import CSP\n",
    "#from helperFunctions import GetCombinedData_HaLT as GetHALT\n",
    "#from helperFunctions import GetCombinedData_CLA as GetCLA\n",
    "#from helperFunctions import GetCombinedData_5F as Get5F\n",
    "#from helperFunctions import GetCombinedData_FreeForm as GetFree\n",
    "\n",
    "from helperFunctions import GetCombinedData_CLA_WBSS as GetCLA\n",
    "from helperFunctions import GetCombinedData_HaLT_WBSS as GetHALT\n",
    "from helperFunctions import GetCombinedData_5F as Get5F\n",
    "from helperFunctions import GetCombinedData_FreeForm_WBSS as GetFree\n",
    "\n",
    "\n",
    "print(\"Available paradigms:\\nHand, Leg, Tongue (HALT)\\nClassic - L/R Hand (CLA)\\nFingers (5F)\")\n",
    "paradigm = input('Enter desired paradigm: ');\n",
    "directoryPath = input('Enter the relative path to data: ');\n",
    "if(paradigm == 'HALT'):\n",
    "    Data, Targets, DataCSP, TargetsCSP, DataICA, TargetsICA = GetHALT(directoryPath, True);\n",
    "    numOutputs = 5;\n",
    "elif(paradigm == 'CLA'):\n",
    "    Data, Targets, DataCSP, TargetsCSP, DataICA, TargetsICA = GetCLA(directoryPath, True);\n",
    "    print(\"############\")\n",
    "    print(\"Processing FreeForm data for further testing\")\n",
    "    FreeData, FreeTargets, FreeDataCSP, FreeTargetsCSP, FreeDataICA, FreeTargetsICA = GetFree('../../../matDown/FREEFORM_DATA/', True);\n",
    "    numOutputs = 2;\n",
    "elif(paradigm == '5F'):\n",
    "    #Data, Targets, DataCSP, TargetsCSP, DataICA, TargetsICA = Get5F(directoryPath, True);\n",
    "    Data, Targets, DataCSP, TargetsCSP = Get5F(directoryPath, True);\n",
    "    numOutputs = 5;\n",
    "else:\n",
    "    print(\"Error: Invalid paradigm {}\".format(paradigm));\n",
    "    quit()\n",
    "\n",
    "enableDropout = True;\n",
    "dropoutPercentage = 0.3;\n",
    "\n",
    "#Run GetCombinedData to pull the datasets from multiple subjects into a single set\n",
    "#Data, Targets, DataCSP, TargetsCSP = GetHALT('../../../matDown/HaLT_Data', True);\n",
    "\n",
    "## Split into train and test sets\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(Data, Targets, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building  and training the model\n",
    "After processing the data, we build the LSTM model.\n",
    "We use 100 units in the first LSTM layer, 50 units in the second LSTM layer, and 2 or 5 dense units in the final layer (depending on the paradigm).\n",
    "\n",
    "We first train the network on non-CSP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 21, 100)           550000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 580,455\n",
      "Trainable params: 580,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "372/372 - 11s - loss: 0.5111 - accuracy: 0.2149\n",
      "Epoch 2/30\n",
      "372/372 - 10s - loss: 0.4969 - accuracy: 0.2505\n",
      "Epoch 3/30\n",
      "372/372 - 10s - loss: 0.4886 - accuracy: 0.2986\n",
      "Epoch 4/30\n",
      "372/372 - 10s - loss: 0.4862 - accuracy: 0.3042\n",
      "Epoch 5/30\n",
      "372/372 - 10s - loss: 0.4811 - accuracy: 0.3163\n",
      "Epoch 6/30\n",
      "372/372 - 11s - loss: 0.4768 - accuracy: 0.3271\n",
      "Epoch 7/30\n",
      "372/372 - 10s - loss: 0.4746 - accuracy: 0.3408\n",
      "Epoch 8/30\n",
      "372/372 - 10s - loss: 0.4664 - accuracy: 0.3577\n",
      "Epoch 9/30\n",
      "372/372 - 11s - loss: 0.4645 - accuracy: 0.3726\n",
      "Epoch 10/30\n",
      "372/372 - 11s - loss: 0.4610 - accuracy: 0.3810\n",
      "Epoch 11/30\n",
      "372/372 - 10s - loss: 0.4563 - accuracy: 0.3913\n",
      "Epoch 12/30\n",
      "372/372 - 10s - loss: 0.4523 - accuracy: 0.4079\n",
      "Epoch 13/30\n",
      "372/372 - 11s - loss: 0.4492 - accuracy: 0.4130\n",
      "Epoch 14/30\n",
      "372/372 - 10s - loss: 0.4494 - accuracy: 0.4024\n",
      "Epoch 15/30\n",
      "372/372 - 11s - loss: 0.4431 - accuracy: 0.4269\n",
      "Epoch 16/30\n",
      "372/372 - 10s - loss: 0.4389 - accuracy: 0.4337\n",
      "Epoch 17/30\n",
      "372/372 - 10s - loss: 0.4362 - accuracy: 0.4384\n",
      "Epoch 18/30\n",
      "372/372 - 10s - loss: 0.4336 - accuracy: 0.4385\n",
      "Epoch 19/30\n",
      "372/372 - 10s - loss: 0.4282 - accuracy: 0.4577\n",
      "Epoch 20/30\n",
      "372/372 - 11s - loss: 0.4219 - accuracy: 0.4678\n",
      "Epoch 21/30\n",
      "372/372 - 11s - loss: 0.4235 - accuracy: 0.4574\n",
      "Epoch 22/30\n",
      "372/372 - 10s - loss: 0.4216 - accuracy: 0.4791\n",
      "Epoch 23/30\n",
      "372/372 - 10s - loss: 0.4144 - accuracy: 0.4923\n",
      "Epoch 24/30\n",
      "372/372 - 10s - loss: 0.4145 - accuracy: 0.4799\n",
      "Epoch 25/30\n",
      "372/372 - 11s - loss: 0.4090 - accuracy: 0.4905\n",
      "Epoch 26/30\n",
      "372/372 - 12s - loss: 0.4094 - accuracy: 0.4876\n",
      "Epoch 27/30\n",
      "372/372 - 11s - loss: 0.4098 - accuracy: 0.4907\n",
      "Epoch 28/30\n",
      "372/372 - 11s - loss: 0.4079 - accuracy: 0.4947\n",
      "Epoch 29/30\n",
      "372/372 - 11s - loss: 0.4018 - accuracy: 0.5014\n",
      "Epoch 30/30\n",
      "372/372 - 11s - loss: 0.4014 - accuracy: 0.5051\n"
     ]
    }
   ],
   "source": [
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,DataTrainRe.shape[1], DataTrainRe.shape[2]), return_sequences=True))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(Dense((numOutputs),activation='sigmoid'))\n",
    "\n",
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "Now, we use the model to predict the outputs for the test set, and compare them to the target outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 4317\n",
      "Incorrect MI Prediction: 1630\n",
      "Percent Accuracy: 72.591%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 1480\n",
      "Incorrect MI Prediction: 1069\n",
      "Percent Accuracy: 58.062%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CSP Data\n",
    "Now, we train the model using the CSP data and then evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "372/372 - 11s - loss: 0.4942 - accuracy: 0.3027\n",
      "Epoch 2/30\n",
      "372/372 - 11s - loss: 0.4665 - accuracy: 0.3728\n",
      "Epoch 3/30\n",
      "372/372 - 10s - loss: 0.4530 - accuracy: 0.4024\n",
      "Epoch 4/30\n",
      "372/372 - 10s - loss: 0.4455 - accuracy: 0.4221\n",
      "Epoch 5/30\n",
      "372/372 - 10s - loss: 0.4306 - accuracy: 0.4606\n",
      "Epoch 6/30\n",
      "372/372 - 10s - loss: 0.4180 - accuracy: 0.4843\n",
      "Epoch 7/30\n",
      "372/372 - 10s - loss: 0.4122 - accuracy: 0.4922\n",
      "Epoch 8/30\n",
      "372/372 - 10s - loss: 0.3954 - accuracy: 0.5189\n",
      "Epoch 9/30\n",
      "372/372 - 10s - loss: 0.3806 - accuracy: 0.5409\n",
      "Epoch 10/30\n",
      "372/372 - 11s - loss: 0.3728 - accuracy: 0.5581\n",
      "Epoch 11/30\n",
      "372/372 - 11s - loss: 0.3611 - accuracy: 0.5729\n",
      "Epoch 12/30\n",
      "372/372 - 11s - loss: 0.3496 - accuracy: 0.5971\n",
      "Epoch 13/30\n",
      "372/372 - 11s - loss: 0.3387 - accuracy: 0.6121\n",
      "Epoch 14/30\n",
      "372/372 - 11s - loss: 0.3320 - accuracy: 0.6090\n",
      "Epoch 15/30\n",
      "372/372 - 11s - loss: 0.3211 - accuracy: 0.6284\n",
      "Epoch 16/30\n",
      "372/372 - 10s - loss: 0.3114 - accuracy: 0.6479\n",
      "Epoch 17/30\n",
      "372/372 - 11s - loss: 0.3068 - accuracy: 0.6538\n",
      "Epoch 18/30\n",
      "372/372 - 12s - loss: 0.2987 - accuracy: 0.6622\n",
      "Epoch 19/30\n",
      "372/372 - 13s - loss: 0.2968 - accuracy: 0.6682\n",
      "Epoch 20/30\n",
      "372/372 - 11s - loss: 0.2895 - accuracy: 0.6795\n",
      "Epoch 21/30\n",
      "372/372 - 11s - loss: 0.2784 - accuracy: 0.6950\n",
      "Epoch 22/30\n",
      "372/372 - 11s - loss: 0.2778 - accuracy: 0.6970\n",
      "Epoch 23/30\n",
      "372/372 - 12s - loss: 0.2699 - accuracy: 0.7044\n",
      "Epoch 24/30\n",
      "372/372 - 11s - loss: 0.2656 - accuracy: 0.7121\n",
      "Epoch 25/30\n",
      "372/372 - 11s - loss: 0.2628 - accuracy: 0.7145\n",
      "Epoch 26/30\n",
      "372/372 - 11s - loss: 0.2562 - accuracy: 0.7247\n",
      "Epoch 27/30\n",
      "372/372 - 12s - loss: 0.2571 - accuracy: 0.7227\n",
      "Epoch 28/30\n",
      "372/372 - 11s - loss: 0.2501 - accuracy: 0.7296\n",
      "Epoch 29/30\n",
      "372/372 - 11s - loss: 0.2492 - accuracy: 0.7368\n",
      "Epoch 30/30\n",
      "372/372 - 11s - loss: 0.2507 - accuracy: 0.7353\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 5076\n",
      "Incorrect MI Prediction: 871\n",
      "Percent Accuracy: 85.354%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 2085\n",
      "Incorrect MI Prediction: 464\n",
      "Percent Accuracy: 81.797%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(DataCSP, TargetsCSP, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Wavelet-BSS Algorithm\n",
    "In the following cell, we train the network on the Wavelet-BSS pre-processed data to compare to the previous approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataICA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-61dff0b3ddc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Split into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mDataTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargetsTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargetsTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataICA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargetsICA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#NumSamples = number of rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataICA' is not defined"
     ]
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(DataICA, TargetsICA, test_size=0.3, random_state=0)\n",
    "\n",
    "#NumSamples = number of rows\n",
    "numSamples = DataTrain.shape[0];\n",
    "if(len(DataTrain.shape) < 3):\n",
    "    numTime = DataTrain.shape[1];\n",
    "    numInputs = 1;\n",
    "else:\n",
    "    numTime = DataTrain.shape[1];\n",
    "    numInputs = DataTrain.shape[2];\n",
    "\n",
    "numSamplesTest = DataTest.shape[0];\n",
    "if(len(DataTest.shape) < 3):\n",
    "    numTimeTest = DataTest.shape[1];\n",
    "    numInputsTest = 1;\n",
    "else:\n",
    "    numTimeTest = DataTest.shape[1];\n",
    "    numInputsTest = DataTest.shape[2];\n",
    "    \n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((numSamples, numTime, numInputs))\n",
    "DataTestRe = DataTest.reshape((numSamplesTest, numTimeTest, numInputsTest))\n",
    "\n",
    "LSTM_EEG_ICA = Sequential()\n",
    "LSTM_EEG_ICA.add(LSTM((100),batch_input_shape=(None,DataTrainRe.shape[1], DataTrainRe.shape[2]), return_sequences=True))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG_ICA.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG_ICA.add(LSTM((50), return_sequences=False))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG_ICA.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG_ICA.add(Dense((numOutputs),activation='sigmoid'))\n",
    "\n",
    "LSTM_EEG_ICA.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG_ICA.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = LSTM_EEG_ICA.fit(DataTrainRe, TargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG_ICA.predict(DataTestRe)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG_ICA.predict(DataTrainRe)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_ICA = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_ICA = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_ICA))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_ICA))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional testing of small FreeForm Datasets\n",
    "The FREEFORM datasets are a collection of datasets (3 of them) that are self-paced. There may not be enough data to train the network on just the FreeForm dataset. If you do train it on that dataset, you might have issues with overfitting. So, if the paradigm was CLA, which is similar to FreeForm, we can evaluate the model on FreeForm as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(paradigm == 'CLA'):\n",
    "    ## Have to check and make sure that the FreeData is the same dimensions as the CLA data\n",
    "    lenFree = FreeDataCSP.shape[2];\n",
    "    if(lenFree < len(DataCSP)):\n",
    "        FreeDataCSP = FreeDataCSP[:, :, 0:DataCSP.shape[2]];\n",
    "        \n",
    "    predictionsFree = LSTM_EEG.predict(FreeDataCSP)\n",
    "    predictionsFree[predictionsFree>0.5] = 1;\n",
    "    predictionsFree[predictionsFree<=0.5] = 0;\n",
    "    comparisonArray = predictionsFree == FreeTargetsCSP;\n",
    "\n",
    "    correctCount = 0\n",
    "    for boolValues in comparisonArray:\n",
    "        if(boolValues[0] & boolValues[1]):\n",
    "            correctCount += 1\n",
    "    falseCount = FreeDataCSP.shape[0] - correctCount\n",
    "\n",
    "\n",
    "    # In[87]:\n",
    "    Accuracy = (correctCount*100/FreeDataCSP.shape[0]);\n",
    "\n",
    "    print(\"#################################\")\n",
    "    print(\"#################################\")\n",
    "    print(\"FreeForm Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCount, falseCount, Accuracy))\n",
    "    print(\"#################################\")\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTrainRe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
