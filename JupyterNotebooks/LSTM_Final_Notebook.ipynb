{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available paradigms:\n",
      "Hand, Leg, Tongue (HALT)\n",
      "Classic - L/R Hand (CLA)\n",
      "Fingers (5F)\n",
      "Enter desired paradigm: CLA\n",
      "Enter the relative path to data: ../../../matDown\n",
      "Processing dataset 1 of 14\n",
      "Processing dataset 2 of 14\n",
      "Processing dataset 3 of 14\n",
      "Processing dataset 4 of 14\n",
      "Processing dataset 5 of 14\n",
      "Processing dataset 6 of 14\n",
      "Processing dataset 7 of 14\n",
      "Processing dataset 8 of 14\n",
      "Processing dataset 9 of 14\n",
      "Processing dataset 10 of 14\n",
      "Processing dataset 11 of 14\n",
      "Processing dataset 12 of 14\n",
      "Processing dataset 13 of 14\n",
      "Processing dataset 14 of 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Documents/GitHub/ECE228ECGProject/JupyterNotebooks/helperFunctions.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return SFa.astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "Processing FreeForm data for further testing\n",
      "Processing dataset 1 of 3\n",
      "Processing dataset 2 of 3\n",
      "Processing dataset 3 of 3\n"
     ]
    }
   ],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Import the helper functions\n",
    "#from helperFunctions import CSP\n",
    "from helperFunctions import GetCombinedData_HaLT as GetHALT\n",
    "from helperFunctions import GetCombinedData_CLA as GetCLA\n",
    "from helperFunctions import GetCombinedData_5F as Get5F\n",
    "from helperFunctions import GetCombinedData_FreeForm as GetFree\n",
    "\n",
    "print(\"Available paradigms:\\nHand, Leg, Tongue (HALT)\\nClassic - L/R Hand (CLA)\\nFingers (5F)\")\n",
    "paradigm = input('Enter desired paradigm: ');\n",
    "directoryPath = input('Enter the relative path to data: ');\n",
    "if(paradigm == 'HALT'):\n",
    "    Data, Targets, DataCSP, TargetsCSP = GetHALT(directoryPath, True);\n",
    "    numOutputs = 5;\n",
    "elif(paradigm == 'CLA'):\n",
    "    Data, Targets, DataCSP, TargetsCSP = GetCLA(directoryPath, True);\n",
    "    print(\"############\")\n",
    "    print(\"Processing FreeForm data for further testing\")\n",
    "    FreeData, FreeTargets, FreeDataCSP, FreeTargetsCSP = GetFree(directoryPath, True);\n",
    "    numOutputs = 2;\n",
    "elif(paradigm == '5F'):\n",
    "    Data, Targets, DataCSP, TargetsCSP = Get5F(directoryPath, True);\n",
    "    numOutputs = 5;\n",
    "else:\n",
    "    print(\"Error: Invalid paradigm {}\".format(paradigm));\n",
    "    quit()\n",
    "\n",
    "enableDropout = True;\n",
    "dropoutPercentage = 0.3;\n",
    "\n",
    "#Run GetCombinedData to pull the datasets from multiple subjects into a single set\n",
    "#Data, Targets, DataCSP, TargetsCSP = GetHALT('../../../matDown/HaLT_Data', True);\n",
    "\n",
    "## Split into train and test sets\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(Data, Targets, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building  and training the model\n",
    "After processing the data, we build the LSTM model.\n",
    "We use 100 units in the first LSTM layer, 50 units in the second LSTM layer, and 2 or 5 dense units in the final layer (depending on the paradigm).\n",
    "\n",
    "We first train the network on non-CSP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 21, 100)           120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 151,102\n",
      "Trainable params: 151,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "370/370 - 5s - loss: 0.6982 - accuracy: 0.5173\n",
      "Epoch 2/30\n",
      "370/370 - 5s - loss: 0.6848 - accuracy: 0.5653\n",
      "Epoch 3/30\n",
      "370/370 - 6s - loss: 0.6784 - accuracy: 0.5721\n",
      "Epoch 4/30\n",
      "370/370 - 6s - loss: 0.6683 - accuracy: 0.5846\n",
      "Epoch 5/30\n",
      "370/370 - 6s - loss: 0.6573 - accuracy: 0.6087\n",
      "Epoch 6/30\n",
      "370/370 - 6s - loss: 0.6533 - accuracy: 0.6111\n",
      "Epoch 7/30\n",
      "370/370 - 6s - loss: 0.6391 - accuracy: 0.6300\n",
      "Epoch 8/30\n",
      "370/370 - 6s - loss: 0.6402 - accuracy: 0.6251\n",
      "Epoch 9/30\n",
      "370/370 - 6s - loss: 0.6240 - accuracy: 0.6425\n",
      "Epoch 10/30\n",
      "370/370 - 6s - loss: 0.6161 - accuracy: 0.6501\n",
      "Epoch 11/30\n",
      "370/370 - 6s - loss: 0.6054 - accuracy: 0.6695\n",
      "Epoch 12/30\n",
      "370/370 - 6s - loss: 0.5886 - accuracy: 0.6685\n",
      "Epoch 13/30\n",
      "370/370 - 6s - loss: 0.5834 - accuracy: 0.6825\n",
      "Epoch 14/30\n",
      "370/370 - 6s - loss: 0.5840 - accuracy: 0.6792\n",
      "Epoch 15/30\n",
      "370/370 - 6s - loss: 0.5733 - accuracy: 0.6912\n",
      "Epoch 16/30\n",
      "370/370 - 6s - loss: 0.5747 - accuracy: 0.6898\n",
      "Epoch 17/30\n",
      "370/370 - 6s - loss: 0.5546 - accuracy: 0.7040\n",
      "Epoch 18/30\n",
      "370/370 - 6s - loss: 0.5542 - accuracy: 0.7114\n",
      "Epoch 19/30\n",
      "370/370 - 6s - loss: 0.5424 - accuracy: 0.7125\n",
      "Epoch 20/30\n",
      "370/370 - 6s - loss: 0.5324 - accuracy: 0.7214\n",
      "Epoch 21/30\n",
      "370/370 - 6s - loss: 0.5399 - accuracy: 0.7194\n",
      "Epoch 22/30\n",
      "370/370 - 6s - loss: 0.5289 - accuracy: 0.7201\n",
      "Epoch 23/30\n",
      "370/370 - 6s - loss: 0.5216 - accuracy: 0.7244\n",
      "Epoch 24/30\n",
      "370/370 - 6s - loss: 0.5160 - accuracy: 0.7326\n",
      "Epoch 25/30\n",
      "370/370 - 6s - loss: 0.5119 - accuracy: 0.7369\n",
      "Epoch 26/30\n",
      "370/370 - 7s - loss: 0.4947 - accuracy: 0.7495\n",
      "Epoch 27/30\n",
      "370/370 - 6s - loss: 0.5020 - accuracy: 0.7397\n",
      "Epoch 28/30\n",
      "370/370 - 6s - loss: 0.5048 - accuracy: 0.7437\n",
      "Epoch 29/30\n",
      "370/370 - 6s - loss: 0.4844 - accuracy: 0.7476\n",
      "Epoch 30/30\n",
      "370/370 - 6s - loss: 0.4804 - accuracy: 0.7547\n"
     ]
    }
   ],
   "source": [
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,DataTrainRe.shape[1], DataTrainRe.shape[2]), return_sequences=True))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(Dense((numOutputs),activation='sigmoid'))\n",
    "\n",
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "Now, we use the model to predict the outputs for the test set, and compare them to the target outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 4837\n",
      "Incorrect MI Prediction: 1082\n",
      "Percent Accuracy: 81.720%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 1490\n",
      "Incorrect MI Prediction: 1047\n",
      "Percent Accuracy: 58.731%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CSP Data\n",
    "Now, we train the model using the CSP data and then evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "370/370 - 6s - loss: 0.6823 - accuracy: 0.5898\n",
      "Epoch 2/30\n",
      "370/370 - 6s - loss: 0.5705 - accuracy: 0.7021\n",
      "Epoch 3/30\n",
      "370/370 - 6s - loss: 0.5072 - accuracy: 0.7452\n",
      "Epoch 4/30\n",
      "370/370 - 6s - loss: 0.4807 - accuracy: 0.7618\n",
      "Epoch 5/30\n",
      "370/370 - 6s - loss: 0.4586 - accuracy: 0.7794\n",
      "Epoch 6/30\n",
      "370/370 - 6s - loss: 0.4394 - accuracy: 0.7937\n",
      "Epoch 7/30\n",
      "370/370 - 6s - loss: 0.4361 - accuracy: 0.7946\n",
      "Epoch 8/30\n",
      "370/370 - 6s - loss: 0.4135 - accuracy: 0.8088\n",
      "Epoch 9/30\n",
      "370/370 - 6s - loss: 0.3904 - accuracy: 0.8196\n",
      "Epoch 10/30\n",
      "370/370 - 6s - loss: 0.3850 - accuracy: 0.8219\n",
      "Epoch 11/30\n",
      "370/370 - 7s - loss: 0.3831 - accuracy: 0.8251\n",
      "Epoch 12/30\n",
      "370/370 - 6s - loss: 0.3738 - accuracy: 0.8268\n",
      "Epoch 13/30\n",
      "370/370 - 6s - loss: 0.3530 - accuracy: 0.8419\n",
      "Epoch 14/30\n",
      "370/370 - 6s - loss: 0.3435 - accuracy: 0.8436\n",
      "Epoch 15/30\n",
      "370/370 - 6s - loss: 0.3385 - accuracy: 0.8525\n",
      "Epoch 16/30\n",
      "370/370 - 6s - loss: 0.3154 - accuracy: 0.8625\n",
      "Epoch 17/30\n",
      "370/370 - 6s - loss: 0.3002 - accuracy: 0.8719\n",
      "Epoch 18/30\n",
      "370/370 - 6s - loss: 0.2898 - accuracy: 0.8780\n",
      "Epoch 19/30\n",
      "370/370 - 6s - loss: 0.2889 - accuracy: 0.8755\n",
      "Epoch 20/30\n",
      "370/370 - 6s - loss: 0.2794 - accuracy: 0.8834\n",
      "Epoch 21/30\n",
      "370/370 - 6s - loss: 0.2774 - accuracy: 0.8834\n",
      "Epoch 22/30\n",
      "370/370 - 6s - loss: 0.2707 - accuracy: 0.8860\n",
      "Epoch 23/30\n",
      "370/370 - 6s - loss: 0.2618 - accuracy: 0.8914\n",
      "Epoch 24/30\n",
      "370/370 - 6s - loss: 0.2550 - accuracy: 0.8973\n",
      "Epoch 25/30\n",
      "370/370 - 6s - loss: 0.2427 - accuracy: 0.8968\n",
      "Epoch 26/30\n",
      "370/370 - 6s - loss: 0.2365 - accuracy: 0.9017\n",
      "Epoch 27/30\n",
      "370/370 - 6s - loss: 0.2406 - accuracy: 0.9008\n",
      "Epoch 28/30\n",
      "370/370 - 6s - loss: 0.2291 - accuracy: 0.9081\n",
      "Epoch 29/30\n",
      "370/370 - 6s - loss: 0.2245 - accuracy: 0.9088\n",
      "Epoch 30/30\n",
      "370/370 - 6s - loss: 0.2143 - accuracy: 0.9081\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 5582\n",
      "Incorrect MI Prediction: 337\n",
      "Percent Accuracy: 94.306%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 2303\n",
      "Incorrect MI Prediction: 234\n",
      "Percent Accuracy: 90.777%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(DataCSP, TargetsCSP, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional testing of small FreeForm Datasets\n",
    "The FREEFORM datasets are a collection of datasets (3 of them) that are self-paced. There may not be enough data to train the network on just the FreeForm dataset. If you do train it on that dataset, you might have issues with overfitting. So, if the paradigm was CLA, which is similar to FreeForm, we can evaluate the model on FreeForm as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "FreeForm Performance:\n",
      "Correct MI Prediction: 1426\n",
      "Incorrect MI Prediction: 700\n",
      "Percent Accuracy: 67.074%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "if(paradigm == 'CLA'):\n",
    "    ## Have to check and make sure that the FreeData is the same dimensions as the CLA data\n",
    "    lenFree = FreeDataCSP.shape[2];\n",
    "    if(lenFree < len(DataCSP)):\n",
    "        FreeDataCSP = FreeDataCSP[:, :, 0:DataCSP.shape[2]];\n",
    "        \n",
    "    predictionsFree = LSTM_EEG.predict(FreeDataCSP)\n",
    "    predictionsFree[predictionsFree>0.5] = 1;\n",
    "    predictionsFree[predictionsFree<=0.5] = 0;\n",
    "    comparisonArray = predictionsFree == FreeTargetsCSP;\n",
    "\n",
    "    correctCount = 0\n",
    "    for boolValues in comparisonArray:\n",
    "        if(boolValues[0] & boolValues[1]):\n",
    "            correctCount += 1\n",
    "    falseCount = FreeDataCSP.shape[0] - correctCount\n",
    "\n",
    "\n",
    "    # In[87]:\n",
    "    Accuracy = (correctCount*100/FreeDataCSP.shape[0]);\n",
    "\n",
    "    print(\"#################################\")\n",
    "    print(\"#################################\")\n",
    "    print(\"FreeForm Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCount, falseCount, Accuracy))\n",
    "    print(\"#################################\")\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 21, 204)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2126"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}