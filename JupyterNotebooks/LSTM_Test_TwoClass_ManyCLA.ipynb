{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two-Class EEG Classification using LSTM-based RNN\n",
    "## Here, we develop a baseline model for using an RNN to perform time-series prediction for one of two motor\n",
    "## imagery (MI) tasks. The data from the file CLA_SubjectJ-170508-3St-LRHand-Inter.mat is processed and we\n",
    "## only keep the data points that pertain to the left and right hand MI tasks. Each of the MI task data consists\n",
    "## of 170 time steps, with each time step consisting of 22 inputs. In other words, we pass the current sample for\n",
    "## of the 22 channels for each time step. At the end of the 170 time step, we send the output of the LSTM layers\n",
    "## to a Dense layer with two outputs. To ease the classification at the outer layer, we have converted the class\n",
    "## into a one-hot encoding of zeros and ones, and use the sigmoid unit at the output to match the output range.\n",
    "\n",
    "## Preliminary results:\n",
    "## Performance on training set is 100% classification rate after around 30 to 40 epochs.\n",
    "## Performance on test set is around 60% - 68%.\n",
    "\n",
    "## Potential problems:\n",
    "## The total amount of data is relatively low. Can it be possible to combine multiple subject's L/R Hand MI data\n",
    "## into one unified data set?\n",
    "## Can also possible increase the size of the data set by doing some data augmentations.\n",
    "## For example, injecting some noise into the existing EEG data to create more test data?\n",
    "\n",
    "## Followup/TODO:\n",
    "## Use pre-implemented common spatial patterns for feature extraction: avialable here: https://github.com/spolsley/common-spatial-patterns\n",
    "## Try using a relatively simple non-linear energy operator as a pre-emphasis step on the data to see if it helps generalize\n",
    "## the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file is used to split data into series of arrays and their corresponding MI task.\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataDir = \"dataset/CLA/\" #replace with folder the CLA files are in\n",
    "dataList = []\n",
    "markersArrayList=[]\n",
    "for file in os.listdir( dataDir ) : #loads all CLA mat files\n",
    "    temp=sio.loadmat(dataDir+file)\n",
    "    tempO=temp['o'][0][0]\n",
    "    tempData=tempO['data']\n",
    "    tempData=np.transpose(tempData)\n",
    "    tempData=tempData[0:21,:] #ignore 22nd channel\n",
    "    dataList.append(tempData)\n",
    "    tempMarkers=tempO['marker']\n",
    "    tempMarkersArray = []\n",
    "    for tempMarker in tempMarkers:\n",
    "        tempMarkersArray.append(tempMarker[0])\n",
    "    tempMarkersArray = np.asarray(tempMarkersArray)\n",
    "    markersArrayList.append(tempMarkersArray)\n",
    "data=np.concatenate(dataList, axis=1)\n",
    "markersArray=np.concatenate(markersArrayList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0: #for 1 loading just 1 .mat file\n",
    "    ## This file is used to split data into series of arrays and their corresponding MI task.\n",
    "    import scipy.io as sio\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    file = sio.loadmat('../mat_files/CLA-SubjectJ-170508-3St-LRHand-Inter.mat') #replace with .mat file name\n",
    "    header=file['__header__']\n",
    "    version=file['__version__']\n",
    "    glob=file['__globals__']\n",
    "    ans=file['ans']\n",
    "\n",
    "\n",
    "    x=file['x']\n",
    "    o=file['o'][0][0]\n",
    "    data=o['data']\n",
    "    data = np.transpose(data)\n",
    "    print(data)\n",
    "    nS=o['nS'][0][0]\n",
    "    #values of structure seem to be 2D numpy arrays, if originally a scalar in Matlab.\n",
    "    #use [0][0] to get scalar.\n",
    "    print(\"Number of samples: {numSamples}\".format(numSamples=nS))\n",
    "    test=o['id'][0] #id value became a 1D array of size 1 for some reason. use [0] to get value\n",
    "    print(\"Dataset ID: {id}\".format(id=test))\n",
    "    chnames=o['chnames'][:,0] #[:,0] converts from 2D array back to 1D array\n",
    "    print(\"Channel names: {channelNames}\".format(channelNames=chnames))\n",
    "    markers = o['marker']\n",
    "    ## The markers are all still individual arrays of size 1x1, so we convert them to an array with single values\n",
    "    markersArray = []\n",
    "    for marker in markers:\n",
    "        markersArray.append(marker[0])\n",
    "    markersArray = np.asarray(markersArray)\n",
    "    #For this dataset, the markers are 0, 1, or 2.\n",
    "    # 1 - Left Hand MI, 2 - Right Hand MI, 3 - Passive State, 0 - Rest (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of index changes: 32336\n",
      "Number of arrays in data split: 32336\n",
      "Number of marker targets: 32336\n"
     ]
    }
   ],
   "source": [
    "## Find the starting indeces where the marker changes\n",
    "changeIdxs = np.where(np.transpose(markersArray)[:-1] != np.transpose(markersArray)[1:])[0]\n",
    "print(\"Number of index changes: {idxChanges}\".format(idxChanges=changeIdxs.shape[0]))\n",
    "## Split the data so that it has its matching marker\n",
    "dataSplit = np.array_split(data, changeIdxs[:-1], axis=1)\n",
    "splitCount = 0\n",
    "for splitData in dataSplit:\n",
    "    splitCount += 1\n",
    "print(\"Number of arrays in data split: {num}\".format(num=splitCount))\n",
    "## Retrieve the marker values for each of the change indeces (changeIdxs)\n",
    "markerTargets = markersArray[changeIdxs];\n",
    "print(\"Number of marker targets: {numTargets}\".format(numTargets=markerTargets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Apply CSP, we first only get the indeces for MI tasks 1 and 2 (left and right hand, respectively.)\n",
    "LeftIdxs = np.where(markerTargets == 1)\n",
    "RightIdxs = np.where(markerTargets == 2)\n",
    "numLeftIdx = LeftIdxs[0].shape\n",
    "maxsteps=220 #most actions have lengths < 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5490, 220, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftData = [];\n",
    "for leftIndex in LeftIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[leftIndex].shape[1] > maxsteps):\n",
    "        continue\n",
    "    else:\n",
    "        diff=maxsteps-dataSplit[leftIndex].shape[1]\n",
    "        temp=np.pad(dataSplit[leftIndex], ((0,0),(0,diff)), mode='constant')\n",
    "        leftData.append(np.transpose(temp))\n",
    "leftData = np.asarray(leftData)\n",
    "leftData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5605, 220, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightData = [];\n",
    "for rightIndex in RightIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[rightIndex].shape[1] > maxsteps):\n",
    "        continue\n",
    "    else:\n",
    "        diff=maxsteps-dataSplit[rightIndex].shape[1]\n",
    "        temp=np.pad(dataSplit[rightIndex], ((0,0),(0,diff)), mode='constant')\n",
    "        rightData.append(np.transpose(temp))\n",
    "rightData = np.asarray(rightData)\n",
    "rightData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep the top 5490 samples, so that left and right data are equal\n",
    "rightDataSub = rightData[1:5491]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrData Shape: (10980, 220, 21)\tmarkerTargets Shape: (10980, 2)\n"
     ]
    }
   ],
   "source": [
    "#Construct the target array and merge the data\n",
    "leftTargets = np.tile(np.array([1,0]),(5490,1))\n",
    "rightTargets = np.tile(np.array([0,1]), (5490,1))\n",
    "markerTargets = np.vstack((leftTargets, rightTargets))\n",
    "lrData = np.vstack((leftData, rightDataSub))\n",
    "\n",
    "#Sanity Check\n",
    "print(\"lrData Shape: {arg1}\\tmarkerTargets Shape: {arg2}\".format(arg1=lrData.shape, arg2=markerTargets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle the data\n",
    "lrData, markerTargets = shuffle(lrData, markerTargets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7686, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "lrDataTrain, lrDataTest, markerTargetsTrain, markerTargetsTest = train_test_split(lrData, markerTargets, test_size=0.3, random_state=1)\n",
    "markerTargetsTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "lrDataTrainRe = lrDataTrain.reshape((lrDataTrain.shape[0], lrDataTrain.shape[1], lrDataTrain.shape[2]))\n",
    "lrDataTestRe = lrDataTest.reshape((lrDataTest.shape[0], lrDataTest.shape[1], lrDataTest.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "## Construct the model\n",
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,lrDataTrainRe.shape[1], lrDataTrainRe.shape[2]), return_sequences=True))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "LSTM_EEG.add(Dense((2),activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 220, 100)          48800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 79,102\n",
      "Trainable params: 79,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7686/7686 - 26s - loss: 0.6938 - acc: 0.5083\n",
      "Epoch 2/5\n",
      "7686/7686 - 26s - loss: 0.6930 - acc: 0.5184\n",
      "Epoch 3/5\n",
      "7686/7686 - 27s - loss: 0.6903 - acc: 0.5387\n",
      "Epoch 4/5\n",
      "7686/7686 - 27s - loss: 0.6880 - acc: 0.5405\n",
      "Epoch 5/5\n",
      "7686/7686 - 26s - loss: 0.6851 - acc: 0.5443\n"
     ]
    }
   ],
   "source": [
    "history = LSTM_EEG.fit(lrDataTrain, markerTargetsTrain, epochs=5,verbose=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest = LSTM_EEG.predict(lrDataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest>0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTest[predictionsTest <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonArrayTest = predictionsTest == markerTargetsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = lrDataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(lrDataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = lrDataTrain.shape[0] - correctCountTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 4189\n",
      "Incorrect MI Prediction: 3497\n",
      "Percent Accuracy: 54.502%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 1674\n",
      "Incorrect MI Prediction: 1620\n",
      "Percent Accuracy: 50.820%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, (correctCountTrain*100/lrDataTrain.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, (correctCountTest*100/lrDataTest.shape[0])))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
