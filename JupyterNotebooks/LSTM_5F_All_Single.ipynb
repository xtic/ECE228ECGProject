{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.   -0.   ... -7.2  -5.94 -0.72]\n",
      " [-0.   -0.   -0.   ... -8.96 -7.28 -7.08]\n",
      " [-0.   -0.   -0.   ...  9.    9.18  9.3 ]\n",
      " ...\n",
      " [-0.   -0.   -0.   ... 27.67  8.23  7.75]\n",
      " [-0.   -0.   -0.   ... 25.41 26.82 29.07]\n",
      " [-0.   -0.   -0.   ... 17.53 16.29 22.08]]\n",
      "[[-0.   -0.   -0.   ... -7.2  -5.94 -0.72]\n",
      " [-0.   -0.   -0.   ... -8.96 -7.28 -7.08]\n",
      " [-0.   -0.   -0.   ...  9.    9.18  9.3 ]\n",
      " ...\n",
      " [-0.   -0.   -0.   ... 27.67  8.23  7.75]\n",
      " [-0.   -0.   -0.   ... 25.41 26.82 29.07]\n",
      " [-0.   -0.   -0.   ... 17.53 16.29 22.08]]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 21, 100)           550400    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 580,855\n",
      "Trainable params: 580,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 21, 100)           550400    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 580,855\n",
      "Trainable params: 580,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "38/38 - 1s - loss: 0.5450 - accuracy: 0.1933\n",
      "38/38 - 1s - loss: 0.5450 - accuracy: 0.1933\n",
      "Epoch 2/2\n",
      "Epoch 2/2\n",
      "38/38 - 1s - loss: 0.4641 - accuracy: 0.4454\n",
      "38/38 - 1s - loss: 0.4641 - accuracy: 0.4454\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 362\n",
      "Incorrect MI Prediction: 233\n",
      "Percent Accuracy: 60.840%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 163\n",
      "Incorrect MI Prediction: 92\n",
      "Percent Accuracy: 63.922%\n",
      "#################################\n",
      "#################################\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 362\n",
      "Incorrect MI Prediction: 233\n",
      "Percent Accuracy: 60.840%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 163\n",
      "Incorrect MI Prediction: 92\n",
      "Percent Accuracy: 63.922%\n",
      "#################################\n",
      "#################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:93: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:93: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "38/38 - 1s - loss: 0.4945 - accuracy: 0.2924\n",
      "38/38 - 1s - loss: 0.4945 - accuracy: 0.2924\n",
      "Epoch 2/2\n",
      "Epoch 2/2\n",
      "38/38 - 1s - loss: 0.4658 - accuracy: 0.4454\n",
      "38/38 - 1s - loss: 0.4658 - accuracy: 0.4454\n",
      "#################################\n",
      "### RESULTS AFTER APPLYING CSP ##\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 357\n",
      "Incorrect MI Prediction: 238\n",
      "Percent Accuracy: 60.000%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 164\n",
      "Incorrect MI Prediction: 91\n",
      "Percent Accuracy: 64.314%\n",
      "#################################\n",
      "#################################\n",
      "#################################\n",
      "### RESULTS AFTER APPLYING CSP ##\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 357\n",
      "Incorrect MI Prediction: 238\n",
      "Percent Accuracy: 60.000%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 164\n",
      "Incorrect MI Prediction: 91\n",
      "Percent Accuracy: 64.314%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "######################################################################\n",
    "######################################################################\n",
    "######################################################################\n",
    "## CSP File from: https://github.com/spolsley/common-spatial-patterns\n",
    "\n",
    "# CSP takes any number of arguments, but each argument must be a collection of trials associated with a task\n",
    "# That is, for N tasks, N arrays are passed to CSP each with dimensionality (# of trials of task N) x (feature vector)\n",
    "# Trials may be of any dimension, provided that each trial for each task has the same dimensionality,\n",
    "# otherwise there can be no spatial filtering since the trials cannot be compared\n",
    "def CSP(*tasks):\n",
    "\tif len(tasks) < 2:\n",
    "\t\tprint(\"Must have at least 2 tasks for filtering.\")\n",
    "\t\treturn (None,) * len(tasks)\n",
    "\telse:\n",
    "\t\tfilters = ()\n",
    "\t\t# CSP algorithm\n",
    "\t\t# For each task x, find the mean variances Rx and not_Rx, which will be used to compute spatial filter SFx\n",
    "\t\titerator = range(0,len(tasks))\n",
    "\t\tfor x in iterator:\n",
    "\t\t\t# Find Rx\n",
    "\t\t\tRx = covarianceMatrix(tasks[x][0])\n",
    "\t\t\tfor t in range(1,len(tasks[x])):\n",
    "\t\t\t\tRx += covarianceMatrix(tasks[x][t])\n",
    "\t\t\tRx = Rx / len(tasks[x])\n",
    "\n",
    "\t\t\t# Find not_Rx\n",
    "\t\t\tcount = 0\n",
    "\t\t\tnot_Rx = Rx * 0\n",
    "\t\t\tfor not_x in [element for element in iterator if element != x]:\n",
    "\t\t\t\tfor t in range(0,len(tasks[not_x])):\n",
    "\t\t\t\t\tnot_Rx += covarianceMatrix(tasks[not_x][t])\n",
    "\t\t\t\t\tcount += 1\n",
    "\t\t\tnot_Rx = not_Rx / count\n",
    "\n",
    "\t\t\t# Find the spatial filter SFx\n",
    "\t\t\tSFx = spatialFilter(Rx,not_Rx)\n",
    "\t\t\tfilters += (SFx,)\n",
    "\n",
    "\t\t\t# Special case: only two tasks, no need to compute any more mean variances\n",
    "\t\t\tif len(tasks) == 2:\n",
    "\t\t\t\tfilters += (spatialFilter(not_Rx,Rx),)\n",
    "\t\t\t\tbreak\n",
    "\t\treturn filters\n",
    "\n",
    "# covarianceMatrix takes a matrix A and returns the covariance matrix, scaled by the variance\n",
    "def covarianceMatrix(A):\n",
    "\tCa = np.dot(A,np.transpose(A))/np.trace(np.dot(A,np.transpose(A)))\n",
    "\treturn Ca\n",
    "\n",
    "# spatialFilter returns the spatial filter SFa for mean covariance matrices Ra and Rb\n",
    "def spatialFilter(Ra,Rb):\n",
    "\tR = Ra + Rb\n",
    "\tE,U = la.eig(R)\n",
    "\n",
    "\t# CSP requires the eigenvalues E and eigenvector U be sorted in descending order\n",
    "\tord = np.argsort(E)\n",
    "\tord = ord[::-1] # argsort gives ascending order, flip to get descending\n",
    "\tE = E[ord]\n",
    "\tU = U[:,ord]\n",
    "\n",
    "\t# Find the whitening transformation matrix\n",
    "\tP = np.dot(np.sqrt(la.inv(np.diag(E))),np.transpose(U))\n",
    "\n",
    "\t# The mean covariance matrices may now be transformed\n",
    "\tSa = np.dot(P,np.dot(Ra,np.transpose(P)))\n",
    "\tSb = np.dot(P,np.dot(Rb,np.transpose(P)))\n",
    "\n",
    "\t# Find and sort the generalized eigenvalues and eigenvector\n",
    "\tE1,U1 = la.eig(Sa,Sb)\n",
    "\tord1 = np.argsort(E1)\n",
    "\tord1 = ord1[::-1]\n",
    "\tE1 = E1[ord1]\n",
    "\tU1 = U1[:,ord1]\n",
    "\n",
    "\t# The projection matrix (the spatial filter) may now be obtained\n",
    "\tSFa = np.dot(np.transpose(U1),P)\n",
    "\treturn SFa.astype(np.float32)\n",
    "######################################################################\n",
    "def GetMinSteps(indeces, data):\n",
    "\tminVal = 9999;\n",
    "\tfor index in indeces:\n",
    "\t\tlength = data[index].shape[1];\n",
    "\t\tif(length < minVal):\n",
    "\t\t\tminVal = length;\n",
    "\treturn minVal\n",
    "######################################################################\n",
    "def GetData(indeces, dataIn, truncateValue):\n",
    "\tdataOut = []\n",
    "\ttruncate = True;\n",
    "\tif truncateValue == 0:\n",
    "\t\ttruncate = False;\n",
    "\tfor idx in indeces:\n",
    "\t\tcurrentData = dataIn[idx]\n",
    "\t\tif truncate:\n",
    "\t\t\tdataOut.append(currentData[:,0:truncateValue])\n",
    "\t\telse:\n",
    "\t\t\tdataOut.append(currentData)\n",
    "\treturn np.asarray(dataOut)\n",
    "######################################################################\n",
    "######################################################################\n",
    "######################################################################\n",
    "\n",
    "\n",
    "enableDropout = True;\n",
    "dropoutPercentage = 0.3;\n",
    "\n",
    "\n",
    "fileNames = ['5F-SubjectB-160309-5St-SGLHand-HFREQ.mat','5F-SubjectB-160311-5St-SGLHand-HFREQ.mat',\\\n",
    "             '5F-SubjectC-160429-5St-SGLHand-HFREQ.mat','5F-SubjectE-160321-5St-SGLHand-HFREQ.mat',\\\n",
    "\t\t\t '5F-SubjectF-160210-5St-SGLHand-HFREQ.mat','5F-SubjectG-160413-5St-SGLHand-HFREQ.mat',\\\n",
    "\t\t\t '5F-SubjectG-160428-5St-SGLHand-HFREQ.mat','5F-SubjectH-160804-5St-SGLHand-HFREQ.mat',\\\n",
    "\t\t\t '5F-SubjectI-160719-5St-SGLHand-HFREQ.mat','5F-SubjectI-160723-5St-SGLHand-HFREQ.mat'];\n",
    "\n",
    "numDatasets = len(fileNames);\n",
    "numDatasets = 1;\n",
    "numEpochs = 2;\n",
    "\n",
    "testAccuracyNoCSP = np.zeros((1,numDatasets))\n",
    "trainAccuracyNoCSP = np.zeros((1,numDatasets))\n",
    "testAccuracyWithCSP = np.zeros((1,numDatasets))\n",
    "trainAccuracyWithCSP = np.zeros((1,numDatasets))\n",
    "\n",
    "for dataset in range(0, numDatasets):\n",
    "\n",
    "\tfileName = fileNames[dataset];\n",
    "\n",
    "\tfile = sio.loadmat('/Users/daniel/Documents/matDown/5F_Data/{}'.format(fileName)) #replace with .mat file name\n",
    "\theader=file['__header__']\n",
    "\tversion=file['__version__']\n",
    "\tglob=file['__globals__']\n",
    "\t#ans=file['ans']\n",
    "\n",
    "\n",
    "\t#x=file['x']\n",
    "\to=file['o'][0][0]\n",
    "\tdata=o['data']\n",
    "\tdata = np.transpose(data)\n",
    "\tdata = data[0:21,:];\n",
    "\tprint(data)\n",
    "\tnS=o['nS'][0][0]\n",
    "\t#values of structure seem to be 2D numpy arrays, if originally a scalar in Matlab.\n",
    "\t#use [0][0] to get scalar.\n",
    "\t#print(\"Number of samples: {numSamples}\".format(numSamples=nS))\n",
    "\ttest=o['id'][0] #id value became a 1D array of size 1 for some reason. use [0] to get value\n",
    "\t#print(\"Dataset ID: {id}\".format(id=test))\n",
    "\tchnames=o['chnames'][:,0] #[:,0] converts from 2D array back to 1D array\n",
    "\t#print(\"Channel names: {channelNames}\".format(channelNames=chnames))\n",
    "\tmarkers = o['marker']\n",
    "\t## The markers are all still individual arrays of size 1x1, so we convert them to an array with single values\n",
    "\tmarkersArray = []\n",
    "\tfor marker in markers:\n",
    "\t\tmarkersArray.append(marker[0])\n",
    "\tmarkersArray = np.asarray(markersArray)\n",
    "\n",
    "\t#################################\n",
    "\t#################################\n",
    "\t#5F interaction paradigm\n",
    "\t#1-thumb MI, 2-index finger MI, 3-middle finger MI, 4-ring finger MI, 5-pinkie finger MI\n",
    "\n",
    "\t#all paradigms\n",
    "\t#99-initial relaxation period\n",
    "\t#91-inter-session rest break period\n",
    "\t#92-experiment end\n",
    "\t#################################\n",
    "\n",
    "\t## Find the starting indeces where the marker changes\n",
    "\tchangeIdxs = np.where(np.transpose(markersArray)[:-1] != np.transpose(markersArray)[1:])[0]\n",
    "\t#print(\"Number of index changes: {idxChanges}\".format(idxChanges=changeIdxs.shape[0]))\n",
    "\t## Split the data so that it has its matching marker\n",
    "\tdataSplit = np.array_split(data, changeIdxs[:-1], axis=1)\n",
    "\tsplitCount = 0\n",
    "\tfor splitData in dataSplit:\n",
    "\t\tsplitCount += 1\n",
    "\t#print(\"Number of arrays in data split: {num}\".format(num=splitCount))\n",
    "\t## Retrieve the marker values for each of the change indeces (changeIdxs)\n",
    "\tmarkerTargets = markersArray[changeIdxs];\n",
    "\t#print(\"Number of marker targets: {numTargets}\".format(numTargets=markerTargets.shape[0]))\n",
    "\n",
    "\t## To Apply CSP, we first only get the indeces for MI tasks 1 and 2 (left and right hand, respectively.)\n",
    "\ttIdx = np.where(markerTargets == 1)[0]\n",
    "\tiIdx = np.where(markerTargets == 2)[0]\n",
    "\tmIdx = np.where(markerTargets == 3)[0]\n",
    "\trIdx = np.where(markerTargets == 4)[0]\n",
    "\tpIdx = np.where(markerTargets == 5)[0]\n",
    "\t#tCount = tIdx.shape\n",
    "\t#print(\"Thumb Marker Count: {}\\tSize of First: ({},{})\".format(tCount, dataSplit[tIdx[0]].shape[0],dataSplit[tIdx[0]].shape[1]))\n",
    "\t#print(\"Thumb Marker Count: {}\\tSize of Second: ({},{})\".format(tCount, dataSplit[tIdx[1]].shape[0],dataSplit[tIdx[1]].shape[1]))\n",
    "\t#print(\"Thumb Marker Count: {}\\tSize of Third: ({},{})\".format(tCount, dataSplit[tIdx[2]].shape[0],dataSplit[tIdx[2]].shape[1]))\n",
    "\n",
    "\n",
    "\ttIdxMin = GetMinSteps(tIdx, dataSplit)\n",
    "\tiIdxMin = GetMinSteps(iIdx, dataSplit)\n",
    "\tmIdxMin = GetMinSteps(mIdx, dataSplit)\n",
    "\trIdxMin = GetMinSteps(rIdx, dataSplit)\n",
    "\tpIdxMin = GetMinSteps(pIdx, dataSplit)\n",
    "\tminValues = [tIdxMin, iIdxMin, mIdxMin, rIdxMin, pIdxMin]\n",
    "\t#minValues\n",
    "\n",
    "\t#Truncate the data to the min size\n",
    "\tminValue = np.min(minValues)\n",
    "\t#print(minValue)\n",
    "\n",
    "\ttData = GetData(tIdx, dataSplit, minValue)\n",
    "\tiData = GetData(iIdx, dataSplit, minValue)\n",
    "\tmData = GetData(mIdx, dataSplit, minValue)\n",
    "\trData = GetData(rIdx, dataSplit, minValue)\n",
    "\tpData = GetData(pIdx, dataSplit, minValue)\n",
    "\t#print(\"Length of tData: {}\".format(len(tData)))\n",
    "\t#print(\"Length of iData: {}\".format(len(iData)))\n",
    "\t#print(\"Length of mData: {}\".format(len(mData)))\n",
    "\t#print(\"Length of rData: {}\".format(len(rData)))\n",
    "\t#print(\"Length of pData: {}\".format(len(pData)))\n",
    "\n",
    "\tminLen = np.min([len(tData), len(iData), len(mData), len(rData), len(pData)])\n",
    "\n",
    "\t##Want to make sure they are balanced, so we keep the minLen values\n",
    "\ttData = tData[0:minLen]\n",
    "\tiData = iData[0:minLen]\n",
    "\tmData = mData[0:minLen]\n",
    "\trData = rData[0:minLen]\n",
    "\tpData = pData[0:minLen]\n",
    "\n",
    "\n",
    "\t# In[68]:\n",
    "\n",
    "\n",
    "\t#Construct the target arrays and merge the data\n",
    "\ttTargets = np.tile(np.array([1,0,0,0,0]),(minLen,1))\n",
    "\tiTargets = np.tile(np.array([0,1,0,0,0]),(minLen,1))\n",
    "\tmTargets = np.tile(np.array([0,0,1,0,0]),(minLen,1))\n",
    "\trTargets = np.tile(np.array([0,0,0,1,0]),(minLen,1))\n",
    "\tpTargets = np.tile(np.array([0,0,0,0,1]),(minLen,1))\n",
    "\n",
    "\tmarkerTargets = np.vstack((tTargets, iTargets, mTargets, rTargets, pTargets))\n",
    "\tFingerData = np.vstack((tData, iData, mData, rData, pData))\n",
    "\n",
    "\t#Sanity Check\n",
    "\t#print(\"FingerData Shape: {arg1}\\tmarkerTargets Shape: {arg2}\".format(arg1=FingerData.shape, arg2=markerTargets.shape))\n",
    "\n",
    "\t## Shuffle the data\n",
    "\tFingerData, markerTargets = shuffle(FingerData, markerTargets, random_state=0)\n",
    "\n",
    "\t## Split into train and test sets\n",
    "\tFingerDataTrain, FingerDataTest, markerTargetsTrain, markerTargetsTest = train_test_split(FingerData, markerTargets, test_size=0.3, random_state=1)\n",
    "\tmarkerTargetsTrain.shape\n",
    "\n",
    "\t## Reshape the data for time-series processing\n",
    "\t## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "\tFingerDataTrainRe = FingerDataTrain.reshape((FingerDataTrain.shape[0], FingerDataTrain.shape[1], FingerDataTrain.shape[2]))\n",
    "\tFingerDataTestRe = FingerDataTest.reshape((FingerDataTest.shape[0], FingerDataTest.shape[1], FingerDataTest.shape[2]))\n",
    "\n",
    "\t## Construct the model\n",
    "\tLSTM_EEG = Sequential()\n",
    "\tLSTM_EEG.add(LSTM((100),batch_input_shape=(None,FingerDataTrainRe.shape[1], FingerDataTrainRe.shape[2]), return_sequences=True))\n",
    "\tLSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "\tLSTM_EEG.add(Dense((5),activation='sigmoid'))\n",
    "\n",
    "\tLSTM_EEG.summary()\n",
    "\tsgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\tLSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\t# In[79]:\n",
    "\n",
    "\n",
    "\thistory = LSTM_EEG.fit(FingerDataTrain, markerTargetsTrain, epochs=numEpochs,verbose=2, batch_size=16)\n",
    "\n",
    "\n",
    "\t# In[80]:\n",
    "\n",
    "\n",
    "\tpredictionsTest = LSTM_EEG.predict(FingerDataTest)\n",
    "\n",
    "\n",
    "\t# In[81]:\n",
    "\n",
    "\n",
    "\tpredictionsTest[predictionsTest>0.5] = 1\n",
    "\n",
    "\n",
    "\t# In[82]:\n",
    "\n",
    "\n",
    "\tpredictionsTest[predictionsTest <= 0.5] = 0\n",
    "\n",
    "\n",
    "\t# In[83]:\n",
    "\n",
    "\n",
    "\tcomparisonArrayTest = predictionsTest == markerTargetsTest\n",
    "\n",
    "\n",
    "\t# In[85]:\n",
    "\n",
    "\n",
    "\tcorrectCountTest = 0\n",
    "\tfor boolValues in comparisonArrayTest:\n",
    "\t\tif(boolValues[0] & boolValues[1]):\n",
    "\t\t\tcorrectCountTest += 1\n",
    "\tfalseCountTest = FingerDataTest.shape[0] - correctCountTest\n",
    "\n",
    "\tpredictionsTrain = LSTM_EEG.predict(FingerDataTrain)\n",
    "\tpredictionsTrain[predictionsTrain>0.5] = 1;\n",
    "\tpredictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "\tcomparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "\tcorrectCountTrain = 0\n",
    "\tfor boolValues in comparisonArrayTrain:\n",
    "\t\tif(boolValues[0] & boolValues[1]):\n",
    "\t\t\tcorrectCountTrain += 1\n",
    "\tfalseCountTrain = FingerDataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "\t# In[87]:\n",
    "\ttrainAcc_noCSP = (correctCountTrain*100/FingerDataTrain.shape[0]);\n",
    "\ttestAcc_noCSP = (correctCountTest*100/FingerDataTest.shape[0]);\n",
    "\n",
    "\t#Save these values into the array\n",
    "\ttrainAccuracyNoCSP[0,dataset] = trainAcc_noCSP;\n",
    "\ttestAccuracyNoCSP[0, dataset] = testAcc_noCSP;\n",
    "\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"#################################\")\n",
    "\n",
    "\n",
    "\t# In[88]:\n",
    "\n",
    "\n",
    "\t## Applying CSP to 5F data\n",
    "\tfilters = CSP(tData, iData, mData, rData, pData)\n",
    "\n",
    "\n",
    "\t# In[90]:\n",
    "\n",
    "\n",
    "\tfiltersArray = np.asarray(filters)\n",
    "\n",
    "\n",
    "\t# In[91]:\n",
    "\n",
    "\n",
    "\tfiltersArray.shape\n",
    "\n",
    "\n",
    "\t# In[92]:\n",
    "\n",
    "\n",
    "\ttData_CSP = np.matmul(np.transpose(filtersArray[0]), tData)\n",
    "\tiData_CSP = np.matmul(np.transpose(filtersArray[1]), iData)\n",
    "\tmData_CSP = np.matmul(np.transpose(filtersArray[2]), mData)\n",
    "\trData_CSP = np.matmul(np.transpose(filtersArray[3]), rData)\n",
    "\tpData_CSP = np.matmul(np.transpose(filtersArray[4]), pData)\n",
    "\n",
    "\n",
    "\t# In[93]:\n",
    "\n",
    "\n",
    "\tFingerData_CSP = np.vstack((tData_CSP, iData_CSP, mData_CSP, rData_CSP, pData_CSP))\n",
    "\n",
    "\n",
    "\t# In[94]:\n",
    "\n",
    "\n",
    "\t#Construct the target arrays and merge the data\n",
    "\ttTargets = np.tile(np.array([1,0,0,0,0]),(minLen,1))\n",
    "\tiTargets = np.tile(np.array([0,1,0,0,0]),(minLen,1))\n",
    "\tmTargets = np.tile(np.array([0,0,1,0,0]),(minLen,1))\n",
    "\trTargets = np.tile(np.array([0,0,0,1,0]),(minLen,1))\n",
    "\tpTargets = np.tile(np.array([0,0,0,0,1]),(minLen,1))\n",
    "\n",
    "\tmarkerTargets = np.vstack((tTargets, iTargets, mTargets, rTargets, pTargets))\n",
    "\n",
    "\n",
    "\t# In[95]:\n",
    "\n",
    "\n",
    "\t## Shuffle the data\n",
    "\tFingerData_CSP, markerTargets_CSP = shuffle(FingerData_CSP, markerTargets, random_state=0)\n",
    "\t## Split into train and test sets\n",
    "\tFingerDataTrain_CSP, FingerDataTest_CSP, markerTargetsTrain_CSP, markerTargetsTest_CSP = train_test_split(FingerData_CSP, markerTargets_CSP, test_size=0.3, random_state=1)\n",
    "\n",
    "\t##Use the same model to train and test\n",
    "\thistory_CSP = LSTM_EEG.fit(FingerDataTrain_CSP, markerTargetsTrain_CSP, epochs=numEpochs,verbose=2, batch_size=16)\n",
    "\n",
    "\n",
    "\t# In[96]:\n",
    "\n",
    "\n",
    "\tpredictionsTest = LSTM_EEG.predict(FingerDataTest_CSP)\n",
    "\n",
    "\n",
    "\t# In[97]:\n",
    "\n",
    "\n",
    "\tpredictionsTest[predictionsTest>0.5] = 1\n",
    "\n",
    "\n",
    "\t# In[98]:\n",
    "\n",
    "\n",
    "\tpredictionsTest[predictionsTest <= 0.5] = 0\n",
    "\n",
    "\n",
    "\t# In[99]:\n",
    "\n",
    "\n",
    "\tcomparisonArrayTest = predictionsTest == markerTargetsTest\n",
    "\n",
    "\n",
    "\t# In[100]:\n",
    "\n",
    "\n",
    "\tcorrectCountTest = 0\n",
    "\tfor boolValues in comparisonArrayTest:\n",
    "\t\tif(boolValues[0] & boolValues[1]):\n",
    "\t\t\tcorrectCountTest += 1\n",
    "\tfalseCountTest = FingerDataTest_CSP.shape[0] - correctCountTest\n",
    "\n",
    "\tpredictionsTrain = LSTM_EEG.predict(FingerDataTrain_CSP)\n",
    "\tpredictionsTrain[predictionsTrain>0.5] = 1;\n",
    "\tpredictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "\tcomparisonArrayTrain = predictionsTrain == markerTargetsTrain;\n",
    "\n",
    "\tcorrectCountTrain = 0\n",
    "\tfor boolValues in comparisonArrayTrain:\n",
    "\t\tif(boolValues[0] & boolValues[1]):\n",
    "\t\t\tcorrectCountTrain += 1\n",
    "\tfalseCountTrain = FingerDataTrain_CSP.shape[0] - correctCountTrain\n",
    "\n",
    "\t#Computing the accuracy\n",
    "\ttrainAcc_wCSP = (correctCountTrain*100/FingerDataTrain_CSP.shape[0]);\n",
    "\ttestAcc_wCSP = (correctCountTest*100/FingerDataTest_CSP.shape[0]);\n",
    "\n",
    "\t#Save these values into the array\n",
    "\ttrainAccuracyWithCSP[0,dataset] = trainAcc_wCSP;\n",
    "\ttestAccuracyWithCSP[0, dataset] = testAcc_wCSP;\n",
    "\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"### RESULTS AFTER APPLYING CSP ##\")\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_wCSP))\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_wCSP))\n",
    "\tprint(\"#################################\")\n",
    "\tprint(\"#################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5F-SubjectB-160309-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectB-160311-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectC-160429-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectE-160321-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectF-160210-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectG-160413-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectG-160428-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectH-160804-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectI-160719-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectI-160723-5St-SGLHand-HFREQ.mat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['5F-SubjectB-160309-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectB-160311-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectC-160429-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectE-160321-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectF-160210-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectG-160413-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectG-160428-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectH-160804-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectI-160719-5St-SGLHand-HFREQ.mat',\n",
       " '5F-SubjectI-160723-5St-SGLHand-HFREQ.mat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63.92156863]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[63.92156863]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAccuracyNoCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64.31372549]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[64.31372549]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAccuracyWithCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.84033613]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[60.84033613]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyNoCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[60.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyWithCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedArray = np.transpose(np.asarray(np.vstack((trainAccuracyNoCSP,testAccuracyNoCSP,trainAccuracyWithCSP, testAccuracyWithCSP))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('5FperSubject.csv', combinedArray, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
