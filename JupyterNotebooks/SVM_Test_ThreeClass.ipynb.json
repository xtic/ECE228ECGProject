{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13.2 -21.6 -13.2 ... -39.6 -40.2 -24.6]\n",
      " [  6.6  -5.4   8.4 ... -10.8 -14.4  -6.6]\n",
      " [ -1.2   2.4   0.6 ...  -5.4  -3.6 -12. ]\n",
      " ...\n",
      " [  5.4  -8.4   6.  ... -10.8  -5.4  -6.6]\n",
      " [ -0.6 -12.   -3.6 ...  -3.6  -1.2  -0. ]\n",
      " [  4.8  -9.6  -0.6 ...   4.2   2.4   1.2]]\n",
      "Number of samples: 621884\n",
      "Dataset ID: 201705101500.32BEA9DD\n",
      "Channel names: [array(['Fp1'], dtype='<U3') array(['Fp2'], dtype='<U3')\n",
      " array(['F3'], dtype='<U2') array(['F4'], dtype='<U2')\n",
      " array(['C3'], dtype='<U2') array(['C4'], dtype='<U2')\n",
      " array(['P3'], dtype='<U2') array(['P4'], dtype='<U2')\n",
      " array(['O1'], dtype='<U2') array(['O2'], dtype='<U2')\n",
      " array(['A1'], dtype='<U2') array(['A2'], dtype='<U2')\n",
      " array(['F7'], dtype='<U2') array(['F8'], dtype='<U2')\n",
      " array(['T3'], dtype='<U2') array(['T4'], dtype='<U2')\n",
      " array(['T5'], dtype='<U2') array(['T6'], dtype='<U2')\n",
      " array(['Fz'], dtype='<U2') array(['Cz'], dtype='<U2')\n",
      " array(['Pz'], dtype='<U2')]\n"
     ]
    }
   ],
   "source": [
    "## This file is used to split data into series of arrays and their corresponding MI task.\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "file = sio.loadmat('dataset/CLA/CLA-SubjectJ-170510-3St-LRHand-Inter.mat') #replace with .mat file name\n",
    "header=file['__header__']\n",
    "version=file['__version__']\n",
    "glob=file['__globals__']\n",
    "ans=file['ans']\n",
    "\n",
    "\n",
    "x=file['x']\n",
    "o=file['o'][0][0]\n",
    "data=o['data']\n",
    "data = np.transpose(data)\n",
    "data = data[0:21,:]\n",
    "print(data)\n",
    "nS=o['nS'][0][0]\n",
    "#values of structure seem to be 2D numpy arrays, if originally a scalar in Matlab.\n",
    "#use [0][0] to get scalar.\n",
    "print(\"Number of samples: {numSamples}\".format(numSamples=nS))\n",
    "test=o['id'][0] #id value became a 1D array of size 1 for some reason. use [0] to get value\n",
    "print(\"Dataset ID: {id}\".format(id=test))\n",
    "chnames=o['chnames'][:,0] #[:,0] converts from 2D array back to 1D array\n",
    "print(\"Channel names: {channelNames}\".format(channelNames=chnames))\n",
    "markers = o['marker']\n",
    "## The markers are all still individual arrays of size 1x1, so we convert them to an array with single values\n",
    "markersArray = []\n",
    "for marker in markers:\n",
    "    markersArray.append(marker[0])\n",
    "markersArray = np.asarray(markersArray)\n",
    "#For this dataset, the markers are 0, 1, or 2.\n",
    "# 1 - Left Hand MI, 2 - Right Hand MI, 3 - Passive State, 0 - Rest (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of index changes: 1800\n",
      "Number of arrays in data split: 1800\n",
      "Number of marker targets: 1800\n"
     ]
    }
   ],
   "source": [
    "## Find the starting indeces where the marker changes\n",
    "changeIdxs = np.where(np.transpose(markersArray)[:-1] != np.transpose(markersArray)[1:])[0]\n",
    "print(\"Number of index changes: {idxChanges}\".format(idxChanges=changeIdxs.shape[0]))\n",
    "## Split the data so that it has its matching marker\n",
    "dataSplit = np.array_split(data, changeIdxs[:-1], axis=1)\n",
    "splitCount = 0\n",
    "for splitData in dataSplit:\n",
    "    splitCount += 1\n",
    "print(\"Number of arrays in data split: {num}\".format(num=splitCount))\n",
    "## Retrieve the marker values for each of the change indeces (changeIdxs)\n",
    "markerTargets = markersArray[changeIdxs];\n",
    "print(\"Number of marker targets: {numTargets}\".format(numTargets=markerTargets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Apply CSP, we first only get the indeces for MI tasks 1 and 2 (left and right hand, respectively.)\n",
    "LeftIdxs = np.where(markerTargets == 1)\n",
    "RightIdxs = np.where(markerTargets == 2)\n",
    "NoneIdxs = np.where(markerTargets == 3)\n",
    "numLeftIdx = LeftIdxs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 170, 21)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftData = [];\n",
    "for leftIndex in LeftIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[leftIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        leftData.append(np.transpose(dataSplit[leftIndex]))\n",
    "leftData = np.asarray(leftData)\n",
    "leftData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 170, 21)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightData = [];\n",
    "for rightIndex in RightIdxs[0]:\n",
    "    #print(leftIndex)\n",
    "    #print(\"Dimensions of index: {ind}\".format(ind=dataSplit[leftIndex].shape))\n",
    "    if(dataSplit[rightIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        rightData.append(np.transpose(dataSplit[rightIndex]))\n",
    "rightData = np.asarray(rightData)\n",
    "rightData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 170, 21)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noneData=[]\n",
    "for noneIndex in NoneIdxs[0]:\n",
    "    if(dataSplit[noneIndex].shape[1] != 170):\n",
    "        continue\n",
    "    else:\n",
    "        noneData.append(np.transpose(dataSplit[noneIndex]))\n",
    "noneData=np.asarray(noneData)\n",
    "noneData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep the top 288 samples, so that left and right data are equal #why start at index 1?\n",
    "keep=284;\n",
    "rightDataSub = rightData[1:(keep+1)]\n",
    "leftDataSub = leftData[1:(keep+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrData Shape: (852, 170, 21)\tmarkerTargets Shape: (852, 1)\n"
     ]
    }
   ],
   "source": [
    "#Construct the target array and merge the data\n",
    "leftTargets = np.tile(np.array([0]),(keep,1))\n",
    "rightTargets = np.tile(np.array([2]), (keep,1))\n",
    "noneTargets = np.tile(np.array([1]), (keep,1))\n",
    "markerTargets = np.vstack((leftTargets, noneTargets, rightTargets))\n",
    "lrData = np.vstack((leftDataSub, noneData, rightDataSub))\n",
    "\n",
    "#Sanity Check\n",
    "print(\"lrData Shape: {arg1}\\tmarkerTargets Shape: {arg2}\".format(arg1=lrData.shape, arg2=markerTargets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle the data\n",
    "lrData, markerTargets = shuffle(lrData, markerTargets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "lrDataTrain, lrDataTest, markerTargetsTrain, markerTargetsTest = train_test_split(lrData, markerTargets, test_size=0.3, random_state=1)\n",
    "markerTargetsTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to be compatible with SVM\n",
    "lrData = lrData.reshape(lrData.shape[0], -1) #reshape so that each row is an action. And contains all the channels and voltages\n",
    "markerTargets = markerTargets.reshape(-1) #reshape to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Shuffle the data\n",
    "lrData, markerTargets = shuffle(lrData, markerTargets, random_state=0)\n",
    "\n",
    "## Split into train and test sets\n",
    "lrDataTrain, lrDataTest, markerTargetsTrain, markerTargetsTest = train_test_split(lrData, markerTargets, test_size=0.3, random_state=1)\n",
    "\n",
    "# SVM Classifier\n",
    "clf = SVC(kernel = 'rbf', random_state = 42)\n",
    "clf.fit(lrDataTrain, markerTargetsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Percent Accuracy: 100.000%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Percent Accuracy: 31.641%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "trainPerc=clf.score(lrDataTrain, markerTargetsTrain)\n",
    "testPerc=clf.score(lrDataTest, markerTargetsTest)\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nPercent Accuracy: {:.3f}%\".format(trainPerc*100))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nPercent Accuracy: {:.3f}%\".format(testPerc*100))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81  0  0]\n",
      " [82  0  0]\n",
      " [93  0  0]]\n",
      "Accuracy score of liking  \n",
      "31.640625\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(markerTargetsTest, clf.predict(lrDataTest))\n",
    "print(cm)\n",
    "print(\"Accuracy score of liking  \")\n",
    "print(accuracy_score(markerTargetsTest, clf.predict(lrDataTest))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 0 1 2 1 0 1 0 0 2 0 0 0 0 2 2 1 1 0 2 1 0 1 2 1 2 1 1 1 0 0 0 0 1 1\n",
      " 1 1 1 0 2 1 1 1 1 1 2 1 0 1 2 0 1 2 0 2 0 1 0 2 0 0 1 2 0 0 2 2 1 1 0 2 0\n",
      " 0 2 1 1 1 1 2 0 0 0 2 0 2 2 0 0 2 0 2 0 0 1 0 0 1 0 2 1 1 0 0 0 1 1 1 0 2\n",
      " 0 0 1 1 0 0 0 0 2 2 0 0 0 2 2 0 2 2 1 1 2 0 0 0 1 1 0 2 1 0 1 0 0 1 0 2 1\n",
      " 1 1 0 0 2 0 1 2 0 2 1 2 1 2 1 1 1 1 1 2 2 2 0 1 0 1 1 2 1 1 1 2 0 1 0 1 2\n",
      " 2 0 1 2 1 2 2 0 1 1 2 2 2 1 2 1 0 0 2 0 1 1 1 0 2 2 2 2 1 0 2 0 2 0 1 2 0\n",
      " 0 0 1 1 0 1 1 1 0 2 2 1 0 2 2 0 2 0 1 2 2 1 1 0 1 0 2 0 1 2 2 1 1 1 1 1 1\n",
      " 2 2 0 2 0 2 2 0 1 1 2 0 2 1 0 0 0 0 1 1 1 2 0 0 0 2 0 0 2 0 1 1 2 1 2 0 2\n",
      " 2 2 2 2 0 2 1 2 1 0 1 1 0 1 1 0 0 0 2 2 2 0 2 1 1 1 0 2 0 1 0 2 1 1 1 2 1\n",
      " 2 2 0 1 1 2 0 0 1 2 0 2 0 0 0 0 2 0 2 2 0 1 2 2 0 1 2 0 0 1 0 0 2 0 1 1 0\n",
      " 0 1 2 0 1 0 2 1 1 2 2 0 1 1 1 1 2 2 2 2 2 0 1 2 1 1 0 0 0 2 2 1 2 1 2 0 2\n",
      " 2 1 1 0 2 1 0 0 1 1 2 0 0 2 1 2 0 1 1 1 2 2 1 0 1 1 2 0 1 2 1 2 0 2 1 0 1\n",
      " 2 0 2 0 1 1 0 0 0 2 2 1 1 0 1 0 0 0 2 2 2 2 1 0 0 0 2 1 2 0 0 1 2 1 2 1 1\n",
      " 1 0 1 2 0 0 2 2 1 0 0 0 0 0 1 0 0 2 2 0 0 0 0 1 0 0 2 2 2 1 0 0 2 0 1 2 0\n",
      " 1 0 1 2 1 1 2 2 0 0 2 1 0 2 2 2 1 1 2 1 2 2 1 0 1 2 0 1 2 1 1 1 2 2 1 0 2\n",
      " 1 1 2 0 1 2 2 1 2 2 0 0 1 1 0 1 0 0 0 0 2 0 2 2 1 0 0 2 1 2 2 1 2 2 2 0 1\n",
      " 2 1 1 1]\n",
      "[2 2 2 0 1 2 1 0 1 0 0 2 0 0 0 0 2 2 1 1 0 2 1 0 1 2 1 2 1 1 1 0 0 0 0 1 1\n",
      " 1 1 1 0 2 1 1 1 1 1 2 1 0 1 2 0 1 2 0 2 0 1 0 2 0 0 1 2 0 0 2 2 1 1 0 2 0\n",
      " 0 2 1 1 1 1 2 0 0 0 2 0 2 2 0 0 2 0 2 0 0 1 0 0 1 0 2 1 1 0 0 0 1 1 1 0 2\n",
      " 0 0 1 1 0 0 0 0 2 2 0 0 0 2 2 0 2 2 1 1 2 0 0 0 1 1 0 2 1 0 1 0 0 1 0 2 1\n",
      " 1 1 0 0 2 0 1 2 0 2 1 2 1 2 1 1 1 1 1 2 2 2 0 1 0 1 1 2 1 1 1 2 0 1 0 1 2\n",
      " 2 0 1 2 1 2 2 0 1 1 2 2 2 1 2 1 0 0 2 0 1 1 1 0 2 2 2 2 1 0 2 0 2 0 1 2 0\n",
      " 0 0 1 1 0 1 1 1 0 2 2 1 0 2 2 0 2 0 1 2 2 1 1 0 1 0 2 0 1 2 2 1 1 1 1 1 1\n",
      " 2 2 0 2 0 2 2 0 1 1 2 0 2 1 0 0 0 0 1 1 1 2 0 0 0 2 0 0 2 0 1 1 2 1 2 0 2\n",
      " 2 2 2 2 0 2 1 2 1 0 1 1 0 1 1 0 0 0 2 2 2 0 2 1 1 1 0 2 0 1 0 2 1 1 1 2 1\n",
      " 2 2 0 1 1 2 0 0 1 2 0 2 0 0 0 0 2 0 2 2 0 1 2 2 0 1 2 0 0 1 0 0 2 0 1 1 0\n",
      " 0 1 2 0 1 0 2 1 1 2 2 0 1 1 1 1 2 2 2 2 2 0 1 2 1 1 0 0 0 2 2 1 2 1 2 0 2\n",
      " 2 1 1 0 2 1 0 0 1 1 2 0 0 2 1 2 0 1 1 1 2 2 1 0 1 1 2 0 1 2 1 2 0 2 1 0 1\n",
      " 2 0 2 0 1 1 0 0 0 2 2 1 1 0 1 0 0 0 2 2 2 2 1 0 0 0 2 1 2 0 0 1 2 1 2 1 1\n",
      " 1 0 1 2 0 0 2 2 1 0 0 0 0 0 1 0 0 2 2 0 0 0 0 1 0 0 2 2 2 1 0 0 2 0 1 2 0\n",
      " 1 0 1 2 1 1 2 2 0 0 2 1 0 2 2 2 1 1 2 1 2 2 1 0 1 2 0 1 2 1 1 1 2 2 1 0 2\n",
      " 1 1 2 0 1 2 2 1 2 2 0 0 1 1 0 1 0 0 0 0 2 0 2 2 1 0 0 2 1 2 2 1 2 2 2 0 1\n",
      " 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(markerTargetsTrain)\n",
    "\n",
    "print(clf.predict(lrDataTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(lrDataTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
