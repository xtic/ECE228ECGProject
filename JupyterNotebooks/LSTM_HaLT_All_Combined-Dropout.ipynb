{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 1 of 29\n",
      "Processing dataset 2 of 29\n",
      "Processing dataset 3 of 29\n",
      "Processing dataset 4 of 29\n",
      "Processing dataset 5 of 29\n",
      "Processing dataset 6 of 29\n",
      "Processing dataset 7 of 29\n",
      "Processing dataset 8 of 29\n",
      "Processing dataset 9 of 29\n",
      "Processing dataset 10 of 29\n",
      "Processing dataset 11 of 29\n",
      "Processing dataset 12 of 29\n",
      "Processing dataset 13 of 29\n",
      "Processing dataset 14 of 29\n",
      "Processing dataset 15 of 29\n",
      "Processing dataset 16 of 29\n",
      "Processing dataset 17 of 29\n",
      "Processing dataset 18 of 29\n",
      "Processing dataset 19 of 29\n",
      "Processing dataset 20 of 29\n",
      "Processing dataset 21 of 29\n",
      "Processing dataset 22 of 29\n",
      "Processing dataset 23 of 29\n",
      "Processing dataset 24 of 29\n",
      "Processing dataset 25 of 29\n",
      "Processing dataset 26 of 29\n",
      "Processing dataset 27 of 29\n",
      "Processing dataset 28 of 29\n",
      "Processing dataset 29 of 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Documents/GitHub/ECE228ECGProject/JupyterNotebooks/helperFunctions.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return SFa.astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "## Construct LSTM using Tensorflow + Keras\n",
    "# Import Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Import the helper functions\n",
    "#from helperFunctions import CSP\n",
    "from helperFunctions import GetCombinedData_HaLT as GetHALT\n",
    "\n",
    "\n",
    "enableDropout = True;\n",
    "dropoutPercentage = 0.3;\n",
    "\n",
    "#Run GetCombinedData to pull the datasets from multiple subjects into a single set\n",
    "Data, Targets, DataCSP, TargetsCSP = GetHALT('../../../matDown/HaLT_Data', True);\n",
    "\n",
    "## Split into train and test sets\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(Data, Targets, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 21, 100)           120800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 151,255\n",
      "Trainable params: 151,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "967/967 - 18s - loss: 0.4822 - accuracy: 0.3045\n",
      "Epoch 2/30\n",
      "967/967 - 17s - loss: 0.4602 - accuracy: 0.3497\n",
      "Epoch 3/30\n",
      "967/967 - 16s - loss: 0.4508 - accuracy: 0.3756\n",
      "Epoch 4/30\n",
      "967/967 - 15s - loss: 0.4431 - accuracy: 0.3888\n",
      "Epoch 5/30\n",
      "967/967 - 15s - loss: 0.4365 - accuracy: 0.3982\n",
      "Epoch 6/30\n",
      "967/967 - 16s - loss: 0.4328 - accuracy: 0.4150\n",
      "Epoch 7/30\n",
      "967/967 - 17s - loss: 0.4281 - accuracy: 0.4194\n",
      "Epoch 8/30\n",
      "967/967 - 17s - loss: 0.4230 - accuracy: 0.4357\n",
      "Epoch 9/30\n",
      "967/967 - 17s - loss: 0.4189 - accuracy: 0.4386\n",
      "Epoch 10/30\n",
      "967/967 - 16s - loss: 0.4163 - accuracy: 0.4509\n",
      "Epoch 11/30\n",
      "967/967 - 16s - loss: 0.4109 - accuracy: 0.4526\n",
      "Epoch 12/30\n",
      "967/967 - 16s - loss: 0.4086 - accuracy: 0.4629\n",
      "Epoch 13/30\n",
      "967/967 - 17s - loss: 0.4052 - accuracy: 0.4730\n",
      "Epoch 14/30\n",
      "967/967 - 17s - loss: 0.4031 - accuracy: 0.4763\n",
      "Epoch 15/30\n",
      "967/967 - 17s - loss: 0.3980 - accuracy: 0.4829\n",
      "Epoch 16/30\n",
      "967/967 - 17s - loss: 0.3945 - accuracy: 0.4924\n",
      "Epoch 17/30\n",
      "967/967 - 17s - loss: 0.3933 - accuracy: 0.4928\n",
      "Epoch 18/30\n",
      "967/967 - 16s - loss: 0.3894 - accuracy: 0.5011\n",
      "Epoch 19/30\n",
      "967/967 - 16s - loss: 0.3884 - accuracy: 0.5061\n",
      "Epoch 20/30\n",
      "967/967 - 16s - loss: 0.3860 - accuracy: 0.5138\n",
      "Epoch 21/30\n",
      "967/967 - 16s - loss: 0.3827 - accuracy: 0.5172\n",
      "Epoch 22/30\n",
      "967/967 - 16s - loss: 0.3838 - accuracy: 0.5151\n",
      "Epoch 23/30\n",
      "967/967 - 16s - loss: 0.3812 - accuracy: 0.5228\n",
      "Epoch 24/30\n",
      "967/967 - 16s - loss: 0.3774 - accuracy: 0.5313\n",
      "Epoch 25/30\n",
      "967/967 - 16s - loss: 0.3743 - accuracy: 0.5335\n",
      "Epoch 26/30\n",
      "967/967 - 17s - loss: 0.3708 - accuracy: 0.5436\n",
      "Epoch 27/30\n",
      "967/967 - 17s - loss: 0.3700 - accuracy: 0.5389\n",
      "Epoch 28/30\n",
      "967/967 - 16s - loss: 0.3695 - accuracy: 0.5461\n",
      "Epoch 29/30\n",
      "967/967 - 16s - loss: 0.3661 - accuracy: 0.5473\n",
      "Epoch 30/30\n",
      "967/967 - 16s - loss: 0.3669 - accuracy: 0.5475\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 11152\n",
      "Incorrect MI Prediction: 4314\n",
      "Percent Accuracy: 72.107%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 4200\n",
      "Incorrect MI Prediction: 2429\n",
      "Percent Accuracy: 63.358%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Construct the model\n",
    "LSTM_EEG = Sequential()\n",
    "LSTM_EEG.add(LSTM((100),batch_input_shape=(None,DataTrainRe.shape[1], DataTrainRe.shape[2]), return_sequences=True))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(LSTM((50), return_sequences=False))\n",
    "if(enableDropout):\n",
    "    LSTM_EEG.add(Dropout(dropoutPercentage))\n",
    "LSTM_EEG.add(Dense((5),activation='sigmoid'))\n",
    "\n",
    "LSTM_EEG.summary()\n",
    "sgd = optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "LSTM_EEG.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results without CSP\n",
    "\n",
    "### Training Performance:\n",
    "Correct MI Prediction: 11152\n",
    "\n",
    "Incorrect MI Prediction: 4314\n",
    "\n",
    "Percent Accuracy: 72.107%\n",
    "#################################\n",
    "\n",
    "\n",
    "### Testing Performance:\n",
    "Correct MI Prediction: 4200\n",
    "\n",
    "Incorrect MI Prediction: 2429\n",
    "\n",
    "Percent Accuracy: 63.358%\n",
    "#################################\n",
    "\n",
    "\n",
    "We can see that training the LSTM on the combined data reduces overfitting but still provides only mediocre test results.\n",
    "\n",
    "In the next cell, we train the same model on the CSP data, which has already been generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "967/967 - 16s - loss: 0.4712 - accuracy: 0.3538\n",
      "Epoch 2/30\n",
      "967/967 - 16s - loss: 0.4099 - accuracy: 0.4938\n",
      "Epoch 3/30\n",
      "967/967 - 17s - loss: 0.3693 - accuracy: 0.5727\n",
      "Epoch 4/30\n",
      "967/967 - 17s - loss: 0.3311 - accuracy: 0.6243\n",
      "Epoch 5/30\n",
      "967/967 - 17s - loss: 0.3148 - accuracy: 0.6443\n",
      "Epoch 6/30\n",
      "967/967 - 16s - loss: 0.2932 - accuracy: 0.6761\n",
      "Epoch 7/30\n",
      "967/967 - 16s - loss: 0.2864 - accuracy: 0.6812\n",
      "Epoch 8/30\n",
      "967/967 - 17s - loss: 0.2750 - accuracy: 0.7003\n",
      "Epoch 9/30\n",
      "967/967 - 17s - loss: 0.2613 - accuracy: 0.7196\n",
      "Epoch 10/30\n",
      "967/967 - 17s - loss: 0.2488 - accuracy: 0.7339\n",
      "Epoch 11/30\n",
      "967/967 - 17s - loss: 0.2364 - accuracy: 0.7454\n",
      "Epoch 12/30\n",
      "967/967 - 17s - loss: 0.2327 - accuracy: 0.7543\n",
      "Epoch 13/30\n",
      "967/967 - 16s - loss: 0.2214 - accuracy: 0.7670\n",
      "Epoch 14/30\n",
      "967/967 - 16s - loss: 0.2153 - accuracy: 0.7791\n",
      "Epoch 15/30\n",
      "967/967 - 16s - loss: 0.2060 - accuracy: 0.7873\n",
      "Epoch 16/30\n",
      "967/967 - 16s - loss: 0.2039 - accuracy: 0.7882\n",
      "Epoch 17/30\n",
      "967/967 - 17s - loss: 0.2034 - accuracy: 0.7916\n",
      "Epoch 18/30\n",
      "967/967 - 17s - loss: 0.1988 - accuracy: 0.7956\n",
      "Epoch 19/30\n",
      "967/967 - 17s - loss: 0.1920 - accuracy: 0.8067\n",
      "Epoch 20/30\n",
      "967/967 - 19s - loss: 0.1952 - accuracy: 0.8013\n",
      "Epoch 21/30\n",
      "967/967 - 19s - loss: 0.1948 - accuracy: 0.8020\n",
      "Epoch 22/30\n",
      "967/967 - 17s - loss: 0.1881 - accuracy: 0.8098\n",
      "Epoch 23/30\n",
      "967/967 - 16s - loss: 0.1850 - accuracy: 0.8113\n",
      "Epoch 24/30\n",
      "967/967 - 16s - loss: 0.1865 - accuracy: 0.8106\n",
      "Epoch 25/30\n",
      "967/967 - 17s - loss: 0.1820 - accuracy: 0.8139\n",
      "Epoch 26/30\n",
      "967/967 - 17s - loss: 0.1767 - accuracy: 0.8208\n",
      "Epoch 27/30\n",
      "967/967 - 17s - loss: 0.1752 - accuracy: 0.8231\n",
      "Epoch 28/30\n",
      "967/967 - 17s - loss: 0.1789 - accuracy: 0.8203\n",
      "Epoch 29/30\n",
      "967/967 - 17s - loss: 0.1723 - accuracy: 0.8272\n",
      "Epoch 30/30\n",
      "967/967 - 17s - loss: 0.1696 - accuracy: 0.8328\n",
      "#################################\n",
      "#################################\n",
      "Training Performance:\n",
      "Correct MI Prediction: 14178\n",
      "Incorrect MI Prediction: 1288\n",
      "Percent Accuracy: 91.672%\n",
      "#################################\n",
      "#################################\n",
      "Testing Performance:\n",
      "Correct MI Prediction: 5934\n",
      "Incorrect MI Prediction: 695\n",
      "Percent Accuracy: 89.516%\n",
      "#################################\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "## Split into train and test sets\n",
    "DataTrain, DataTest, TargetsTrain, TargetsTest = train_test_split(DataCSP, TargetsCSP, test_size=0.3, random_state=0)\n",
    "\n",
    "## Reshape the data for time-series processing\n",
    "## Syntax np.reshape((numExamples, numTimeSteps, numInputs/numFeatures))\n",
    "DataTrainRe = DataTrain.reshape((DataTrain.shape[0], DataTrain.shape[1], DataTrain.shape[2]))\n",
    "DataTestRe = DataTest.reshape((DataTest.shape[0], DataTest.shape[1], DataTest.shape[2]))\n",
    "\n",
    "history = LSTM_EEG.fit(DataTrain, TargetsTrain, epochs=30,verbose=2, batch_size=16)\n",
    "\n",
    "predictionsTest = LSTM_EEG.predict(DataTest)\n",
    "\n",
    "predictionsTest[predictionsTest>0.5] = 1\n",
    "predictionsTest[predictionsTest <= 0.5] = 0\n",
    "comparisonArrayTest = predictionsTest == TargetsTest\n",
    "\n",
    "correctCountTest = 0\n",
    "for boolValues in comparisonArrayTest:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTest += 1\n",
    "falseCountTest = DataTest.shape[0] - correctCountTest\n",
    "\n",
    "predictionsTrain = LSTM_EEG.predict(DataTrain)\n",
    "predictionsTrain[predictionsTrain>0.5] = 1;\n",
    "predictionsTrain[predictionsTrain<=0.5] = 0;\n",
    "comparisonArrayTrain = predictionsTrain == TargetsTrain;\n",
    "\n",
    "correctCountTrain = 0\n",
    "for boolValues in comparisonArrayTrain:\n",
    "    if(boolValues[0] & boolValues[1]):\n",
    "        correctCountTrain += 1\n",
    "falseCountTrain = DataTrain.shape[0] - correctCountTrain\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "trainAcc_noCSP = (correctCountTrain*100/DataTrain.shape[0]);\n",
    "testAcc_noCSP = (correctCountTest*100/DataTest.shape[0]);\n",
    "\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Training Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTrain, falseCountTrain, trainAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")\n",
    "print(\"Testing Performance:\\nCorrect MI Prediction: {}\\nIncorrect MI Prediction: {}\\nPercent Accuracy: {:.3f}%\".format(correctCountTest, falseCountTest, testAcc_noCSP))\n",
    "print(\"#################################\")\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results with CSP\n",
    "---\n",
    "### Training Performance:\n",
    "Correct MI Prediction: 14178\n",
    "\n",
    "Incorrect MI Prediction: 1288\n",
    "\n",
    "Percent Accuracy: 91.672%\n",
    "\n",
    "---\n",
    "\n",
    "### Testing Performance:\n",
    "Testing Performance:\n",
    "    \n",
    "Correct MI Prediction: 5934\n",
    "\n",
    "Incorrect MI Prediction: 695\n",
    "\n",
    "Percent Accuracy: 89.516%\n",
    "\n",
    "---\n",
    "We see that CSP greatly increases the accuracy for both the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97.14285714, 94.7107438 , 96.63865546, 94.7107438 , 97.68595041,\n",
       "        86.12521151, 88.09917355, 85.95890411, 91.86046512, 81.15702479]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyNoCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98.48739496, 91.90082645, 97.14285714, 87.27272727, 92.56198347,\n",
       "        96.27749577, 98.34710744, 74.14383562, 87.20930233, 81.65289256]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracyWithCSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedArray = np.transpose(np.asarray(np.vstack((trainAccuracyNoCSP,testAccuracyNoCSP,trainAccuracyWithCSP, testAccuracyWithCSP))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('5FperSubject_Dropout.csv', combinedArray, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/davalenc/ProjectFiles/ECE228ECGProject/JupyterNotebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((3,2,3))+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[:, :, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5., 5.],\n",
       "        [5., 5.]],\n",
       "\n",
       "       [[5., 5.],\n",
       "        [5., 5.]],\n",
       "\n",
       "       [[5., 5.],\n",
       "        [5., 5.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
